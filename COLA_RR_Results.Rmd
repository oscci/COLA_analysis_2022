---
title: "Inconsistent language lateralisation -  testing the dissociable language laterality hypothesis using behaviour and lateralised cerebral blood flow"
author: "COLA consortium*"
date: "1 Mar 2022"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

*Adam J. Parker^1a^, Zoe V. J. Woodhead^1a^ , David P. Carey^2^, Margriet A. Groen^3^, Eva Gutierrez-Sigut^4,7^, Jessica Hodgson^5^, John Hudson^6^, Emma M. Karlsson^2^, Mairéad MacSweeney^7^, Heather Payne^7^, Nuala Simpson^1^, Paul A. Thompson^1^, Kate E. Watkins^1^, Ciara Egan^1,2^, Jack H. Grant^1,6^, Sophie Harte^1,7^, Brad T. Hudson^1,3^, Dorothy V. M. Bishop^1b^  

^a^ Joint first author  
^b^ Corresponding author  

^1^Department of Experimental Psychology, University of Oxford  
^2^School of Psychology, Bangor University  
^3^Department of Psychology, Lancaster University  
^4^Department of Psychology, University of Essex  
^5^Lincoln Medical School, University of Lincoln  
^6^School of Psychology, University of Lincoln  
^7^Deafness, Cognition and Language Research Centre, University College London  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


# If the package is not installed, install it. If it is installed, load it.
usePackage <- function(p) {
    if (!is.element(p, installed.packages()[,1]))
        install.packages(p, dep = TRUE)
    require(p, character.only = TRUE)
}
usePackage('dplyr')
usePackage('tidyr')
usePackage('ggplot2')
usePackage('yarrr') #for pirate plots
usePackage("osfr") #for reading files from OSF
usePackage("stringr")
usePackage("table1") #useful for making simple tables of demographic etc
usePackage("ggExtra") #for marginal plots
usePackage("ggpubr")
usePackage("patchwork") #for combining plots in ggplot
usePackage("flextable")

usePackage("tidyverse")
usePackage("here") #to find filepaths
usePackage("kableExtra")

usePackage("ggstatsplot")
usePackage("MASS") #includes boxcox function
usePackage("MBESS")
usePackage("nlme")
usePackage("semPower")
usePackage("semTools")
usePackage("bookdown")
usePackage("lavaan")
usePackage("semPlot")

usePackage("officer")
usePackage("corrr") #added by DB for easy correlations
usePackage("plyr")
usePackage("qpcR") #used in Kievit script
usePackage("ggpubr")
usePackage("reshape2")
usePackage("mice")
usePackage("MVN") #multivariate normality
usePackage("viridis") #possibly for control over colours in ggplot
usePackage("hrbrthemes") #for fancy themes in ggplot?
usePackage("DiagrammeR") #for participant recruitment flowchart
usePackage('DiagrammeRsvg')
usePackage('magrittr')
usePackage('rsvg')

#hrbrthemes::import_roboto_condensed()  #not sure if needed - was in example with ggplot

options(scipen=999)

tabnumber <-0 #initialise counter for tables
fignumber <-0 # initialise counter for figs
suppfignumber<-0 
```

<!--- GENERIC FUNCTIONS START -->
```{r pformat, echo=F}
#function to format p-values
pformat=function(myp){
  pout <- paste('p =',round(myp,3))
  if(myp<.001){pout = 'p < .001'}
  return(pout)
}
```

```{r pformat2, echo=F}
#function to format p-values, without the 'p = ' bit
pformat2=function(myp){
  pout <- round(myp,3)
  if(myp<.001){pout ='< .001'}
  return(pout)
}
```


```{r LIdensityplot,echo=F}
#generic density plot, subsetted by handedness or another categorical variable
#includes line showing zero point.
#takes as input allsum; temp and cattemp are dummy columns that are assigned prior to call to the function
doLIplot <- function(myfile,temp,cattemp,mysubsetname,mysubsetlabels,xlabel,xrange){
LI.plot <- ggplot(myfile, aes(x=temp, color=as.factor(cattemp))) +
  geom_density()+
  xlab(xlabel)+
  geom_vline(xintercept = 0,lty=3)+
  xlim(xrange)+
  scale_color_manual(name=mysubsetname,
                       labels=mysubsetlabels,
                       values=c("blue","red"))


return(LI.plot)
}
```


```{r densfunction,echo=F}
#Function to do a density plot for specified file coded by group
#(Not sure if output differs from previous function! - need to check)

dodensity <- function(mydat,myx,myy,mygroup,namex,namey,namegroup,grouplabels,mylines,mytitle){
  
 
scatterdens <- ggplot(mydat,aes(x = myx, y = myy,col=mygroup)) + 
  geom_point(shape = 4,  size = 1)+
  scale_color_manual(name=namegroup,
                       labels=grouplabels,
                       values=c("blue","red"))+
  labs(x = namex,y=namey)+
  ggtitle(mytitle) 
if (mylines==1){
   scatterdens<-scatterdens+geom_abline(intercept = 0, slope = 1)
}
if (mylines==2){
   scatterdens<-scatterdens+geom_hline(yintercept = 0,linetype="dashed")+
   geom_vline(xintercept = 0,linetype="dashed")
}

 
dens1 <- ggplot(mydat, aes(x = myx, fill = mygroup)) + 
  geom_density(alpha = 0.4) + 
  geom_vline(xintercept = 0, linetype="dotted")+
  theme_void() + 
  theme(legend.position = "none")

dens2 <- ggplot(mydat, aes(x = myy, fill = mygroup)) + 
  geom_density(alpha = 0.4) + 
  geom_vline(xintercept = 0, linetype="dotted")+
  theme_void() + 
  theme(legend.position = "none") + 
  coord_flip()

alldens<-dens1 + plot_spacer() + scatterdens + dens2 + 
  plot_layout(ncol = 2, nrow = 2, widths = c(4, 1), heights = c(1, 4))

#ggsave(paste0(mydir,"/",figdir,"/",plotname,".png"),width = 5, height = 4)
return(alldens)
}
```

```{r filltable,echo=F,warning=F}
#Generate function to populate summary data frame - same steps for all online tasks
#This function also repurposed for ftcd
populate <- function(mydf,mytask,mysummary,writecolnum,tasktype){
  if(tasktype=='beh'){
w<-which(colnames(mydf)==paste0(mytask,'.zlat'))
x<-which(colnames(mydf)==paste0('exclude',mytask))
odds<-which(colnames(mydf)==paste0(mytask,'.odd.zlat'))
evens<-which(colnames(mydf)==paste0(mytask,'.even.zlat'))
  }
    if(tasktype=='ftcd'){
w<-which(colnames(mydf)==paste0(mytask,'_mean_LI'))
x<-which(colnames(mydf)==paste0(mytask,'_exclude'))
odds<-which(colnames(mydf)==paste0(mytask,'_mean_odd'))
evens<-which(colnames(mydf)==paste0(mytask,'_mean_even'))
  }
  
thisdat<-mydf[mydf[,x]==0,]
thisdat$thiscol<-thisdat[,w]
normp <-shapiro.test(thisdat$thiscol)$p.value
nL <- nrow(filter(thisdat,Rhanded==0))
nR <- nrow(filter(thisdat,Rhanded==1))
tL<- t.test(thisdat$thiscol[thisdat$Rhanded==0])
tR<- t.test(thisdat$thiscol[thisdat$Rhanded==1])
sdL<-round(sd(thisdat$thiscol[thisdat$Rhanded==0],na.rm=T),2)
sdR<-round(sd(thisdat$thiscol[thisdat$Rhanded==1],na.rm=T),2)
sdall <-round(sd(thisdat$thiscol,na.rm=T),2) 
tcompare <- t.test(thisdat$thiscol~thisdat$Rhanded,alternative='less')
#write N for L and R in row 1 of online summary
mysummary[1,writecolnum]<-paste0(nL,' LH + ',nR,' RH')
mysummary[2,writecolnum]<-paste0(round(mean(thisdat$thiscol,na.rm=T),2)," (",sdall,")")
mysummary[3,writecolnum]<-paste0(round(skew(thisdat$thiscol)[1],2),' (',pformat(skew(thisdat$thiscol)[4]),')')
mysummary[4,writecolnum]<-paste0(round(kurtosis(thisdat$thiscol)[1],2),' (',pformat(kurtosis(thisdat$thiscol)[4]),')')
mysummary[5,writecolnum]<-pformat(normp)
mysummary[6,writecolnum]<-paste0(round(tL$estimate,2)," (",sdL,")")
mysummary[7,writecolnum]<-paste0(round(tR$estimate,2)," (",sdR,")")
mysummary[8,writecolnum]<- paste0('t = ',round(tL$statistic,1),'; ', pformat(tL$p.value))
mysummary[9,writecolnum]<- paste0('t = ',round(tR$statistic,1),'; ', pformat(tR$p.value))
mysummary[10,writecolnum]<- paste0('t = ',-round(tcompare$statistic,1),'; ', pformat(tcompare$p.value))
mysummary[11,writecolnum]<- round(cor(thisdat[,odds],thisdat[,evens],use='complete.obs'),3)



return(mysummary)
}
```

```{r trianglefunction,echo=F}
#Gets upper triangle of a correlation matrix
 get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat,diag=T)]<- NA
    return(cormat)
  }
```



```{r heatmapfunction,echo=F}
#Make a heatmap
# http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
makeheatmap <- function(mydf,mycols){
cormat <- cor(mydf[,mycols],use="complete.obs")

melted_cormat <- melt(cormat)
head(melted_cormat)

upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix

melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Heatmap

ggheatmap <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed()

myheatmap <- ggheatmap + 
geom_text(aes(Var2, Var1, label = round(value,3)), color = "black", size = 4) +
theme(
  axis.title.x = element_blank(),
  axis.title.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.border = element_blank(),
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  legend.justification = c(1, 0),
  legend.position = c(0.5, 0.7),
  legend.direction = "horizontal")+
  guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))

return(myheatmap)}
```


```{r bivplotfunction,echo=F,warning=F}
#Function to make a bivariate plot subdivided by group, with spearman correlation in plot. Handedness coded by shape.

#When we call this function we have already created temporary x and y cols (tempx and tempy) to be used in this function
bivplot<-function(bivdat,name1,name2){
#correlations for each group
cor1 <- cor.test(bivdat$tempx[bivdat$Group==1],bivdat$tempy[bivdat$Group==1],method="spearman")
cor2 <- cor.test(bivdat$tempx[bivdat$Group==2],bivdat$tempy[bivdat$Group==2],method="spearman")
lab1<- paste0("Group 1: rs = ",round(cor1$estimate,3))
lab2<- paste0("Group 2: rs = ",round(cor2$estimate,3))   

myplot <- ggplot(bivdat, aes(x=tempx, y=tempy, color=Handedness,shape=as.factor(Group))) +
  xlab(name1)+
   ylab(name2)+
  xlim(-10,10)+
  ylim(-10,10)+
  geom_point()+
  scale_shape_manual(name="Group (random)",
                     labels=c(1,2),
                     values=c(1,16))+
  scale_color_manual(name="Handedness",
                       labels=c("Left","Right"),
                       values=c("blue","red"))+
  geom_hline(yintercept=0,linetype="dashed")+
   geom_vline(xintercept=0,linetype="dashed")+
  annotate("text", x=-5, y=9.5, label= lab1,size=3) +
  annotate("text", x=-5, y=8, label= lab2,size=3)   
  return(myplot)
}


```


```{r bivplotfunction2,echo=F,warning=F}
#Function to make a bivariate plot colour coded by handedness, with spearman correlation in plot

#When we call this function we have already created temporary x and y cols (tempx and tempy) to be used in this function
bivplot2<-function(bivdat,name1,name2){
#correlations for each group
cor1 <- cor.test(bivdat$tempx[bivdat$Rhanded==0],bivdat$tempy[bivdat$Rhanded==0],method="spearman")
cor2 <- cor.test(bivdat$tempx[bivdat$Rhanded==1],bivdat$tempy[bivdat$Rhanded==1],method="spearman")
lab1<- paste0("L-handers: rs = ",round(cor1$estimate,2))
lab2<- paste0("R-handers: rs = ",round(cor2$estimate,2))   

myplot <- ggplot(bivdat, aes(x=tempx, y=tempy, color=Handedness)) +
  xlab(name1)+
   ylab(name2)+
  xlim(-10,10)+
  ylim(-10,10)+
   geom_point(shape=1, size=1)+
  scale_color_manual(name="Handedness",
                       labels=c("Left","Right"),
                       values=c("blue","red"))+
  geom_hline(yintercept=0,linetype="dashed")+
   geom_vline(xintercept=0,linetype="dashed")+
  annotate("text", x=-5.5, y=9.5, label= lab1,size=2.8) +
  annotate("text", x=-5.5, y=8, label= lab2,size=2.8)   
  return(myplot)
}


```

```{r scatterplusfunction,echo=F}
#Function for doing scatterplot with marginal density distributions
doscatterplus <- function(myfile, taskname,mycolnames,myrange){ #myfile contains group in col 1 and the 2 cols to plot in cols 2-3
colnames(myfile)[2:4]<- mycolnames

r <- round(cor(myfile$Odd,myfile$Even,use="complete.obs",method="spearman"),3)
myt<-t.test(myfile$All~myfile$Handed)
myt2 <- t.test(myfile$All) #single group t-test
text1 <- paste0('Mean diff from zero: \nt = ',round(myt2$statistic,2),"; ", pformat(myt2$p.value))
text2 <- paste0('L vs R handers \n(all trials):\n t = ',round(myt$statistic,2),"; ", pformat(myt$p.value))
text3 <-paste0('Spearman rho: ',r)
p <- ggplot(myfile, aes_string('Odd','Even')) +
  aes_string(colour = 'Handed') +
  geom_point() + theme_bw(15)+
  annotate("text", x = 3.2, y = -3,label=text3,size=3)+
  annotate("text", x = -2.5, y = 5.5,label=text1,size=3)+
  annotate("text", x = -2.5, y = 3.5,label=text2,size=3)+
  geom_hline(yintercept=0,linetype="dashed",colour="grey")+
  geom_vline(xintercept=0,linetype="dashed",colour="grey")+
  xlim(myrange)+
  ylim(myrange)+
  ggtitle(taskname)

p2 <- ggExtra::ggMarginal(
  p,
  type = 'density',
  margins = 'both',
  size = 5,
  groupColour = TRUE,
  groupFill = TRUE
)
return(p2)

}

```

```{r makeSEMtabfunction,echo=F}
#Function to make tidy table for SEM output for model with one group
#This is now largely superseded by bigsummary, though SEMtab has more complete information
makeSEMtab <- function(myfit){
ss<- summary(myfit)$PE
 srow<-nrow(ss)
 scol<-ncol(ss)
mySEMout <-ss[,-4]
mySEMout[,4:7]<-round(mySEMout[,4:7],3)

#add fit measures
myfitmeasures<-c('CFI','rmsea','chisq','DF') #can modify this if need be
fm<-fitmeasures(myfit,myfitmeasures)
for(i in 1:length(myfitmeasures)){
mySEMout[(i+srow),1]<-myfitmeasures[i] #write name of fit measure to col 1
mySEMout[(i+srow),2]<-round(fm[i],3) #write value to col 2
}
return(mySEMout)
}
```

```{r makeSEMtab2function,echo=F}
#Table for SEM output side by side for 2 groups
makeSEMtab2 <- function(myfit,mygroups){
ss<- summary(myfit)$PE
 srow<-nrow(ss)
 scol<-ncol(ss)
mySEMout <- cbind(ss[1:(srow/2),c(1:3,(scol-3):scol)],ss[(1+srow/2):srow,c((scol-3):scol)])
mySEMout[,4:11]<-round(mySEMout[,4:11],3)
mySEMout[(srow/2+1):(srow/2+4),]<-NA #additional rows for fit measures


#add fit measures
myfitmeasures<-c('CFI','rmsea','chisq','DF') #can modify this if need be
fm<-fitmeasures(myfit,myfitmeasures)
for(i in 1:length(myfitmeasures)){
mySEMout[(i+srow/2),1]<-myfitmeasures[i] #write name of fit measure to col 1
mySEMout[(i+srow/2),2]<-round(fm[i],3) #write value to col 2
}

#make different col headers for the 2 groups
colnames(mySEMout)[4:7]<-paste0(colnames(mySEMout)[4:7],mygroups[1])
colnames(mySEMout)[8:11]<-paste0(colnames(mySEMout)[8:11],mygroups[2])
return(mySEMout)
}
```


```{r add-to-bigsummaryfunction,echo=F}
#This function adds to the bigsummary data frame - it takes the paths and a few diagnostic stats from myfit and writes to writecol in bigsummary. If comparisonfit is specified, it will also do a chi square comparison with that model and put p value in final row.
addmodel <- function(bigsummary,myfit,comparisonfit,myfitname,writecol){
  colnames(bigsummary)[writecol]<-myfitname #name of the model as column name
ss<- summary(myfit)$PE #get coefficients from current model
bigsummary[1,writecol]<-lavInspect(myfit,'nobs') #sample size goes in 1st row
thisrow<-1 #initialise counter for factor loadings
#if a relevant path exists, put its estimate in correct row; first Factor1, then Factor2
#If  no path in the model, it just skips it
for (f in 1:2){
for (m in 1:6){
  thisrow<-thisrow+1
  w<-which(ss$lhs==paste0('f',f))
  x<-which(substr(ss$rhs,1,1) == LETTERS[m])
  myrow<-intersect(w,x)[1]
  bigsummary[thisrow,writecol]<-round(ss$est[myrow],3)
}
}
#Correlation between factors is added (if it exists)
myrow<-intersect(which(ss$lhs=='f1'),which(ss$rhs=='f2'))[1]
if(length(myrow)>0){
  bigsummary[14,writecol]<-round(ss$est[myrow],3)
}

wantfits <- c('CFI','rmsea','chisq','df') #fit indices to include
#NB there are many other fit indices we could add, but if we do, would need to modify bigsummary.
#Currently script assumes we will have these 4 fit indices 

fm<-fitmeasures(myfit,wantfits)
#find first row to write to
r<-which(bigsummary[,1]==wantfits[1]) #find row corresponding to first fit index
bigsummary[r:(r+length(wantfits)-1),writecol]<-fm #write the fit indices in successive rows, starting with r



#because this is data.frame, all values in a column must be same format.
#Starts numeric, but that means Nobs and DF is shown to 3 decimal places. 
#Can remove decimal places with line below, but then all values become characters
#In practice, I've found trying to format creates problems, so better to format bigsummary outside this function
#bigsummary[1,mycol]<-as.character(round(bigsummary[1,mycol],0))

return(bigsummary)
}
```

```{r factorscores,echo=F}
#FUnction to extract factor scores and plot them and save plot
makefactorplot <- function(myfit,fitname,thisdat){
lastc <- ncol(thisdat)
myfacs<-predict(myfit)
myfacs<-as.data.frame(myfacs)
colnames(myfacs)<-c("Factor1","Factor2")
w<-which(colnames(ddati)=='Factor1') #check if we already have col for factors
if(length(w)==0){
thisdat<-cbind(thisdat,as.data.frame(myfacs))
}
if(length(w)>0){
  thisdat$Factor1 <- as.data.frame(myfacs[,1])
  thisdat$Factor2 <- as.data.frame(myfacs[,2])
}

plotf1f2 <- myscatter(thisdat$Factor1,thisdat$Factor2,xlabel='Factor1',ylabel='Factor2',thisdat)

plotname <- paste0(mydir,"/",figdir,"/factors_",fitname,".png")

ggsave(plotname,width = 5, height = 3)
return(thisdat)
}

```


```{r densplotsfunction,echo=F}
#overlapping density plots 
densplots<-function(mydat,thiscol,thisgroup,mylab){
  myplot <- ggplot(data=ddati, aes_string(x=thiscol, color=thisgroup, fill=thisgroup)) +
  geom_density(alpha=0.5,kernel="gaussian") +
  annotate(geom="text", x=-6, y=.3, label=mylab,hjust=0,size=4)+
  #scale_fill_viridis(discrete=TRUE) +
  #scale_color_viridis(discrete=TRUE) +
  xlim(-6,8)+
    ylim(0,.36)+
  geom_vline(xintercept = 0,linetype="dotted")+
  theme(axis.title.x=element_blank(),
        axis.title.y=element_blank(),legend.position="none")
  return(myplot)
}
```
<!--- GENERIC FUNCTIONS END -->



 
```{r readcombined,echo=F}

mydir <- "~/Dropbox/COLA_RR_Analysis"
alldir <- c(mydir,"~/Dropbox/COLA_RR_Analysis/05-writeup/05.1-supplementary")

figdir <-"03-graphic-outputs" 

readfile<-paste0(alldir[1],"/02-data/combined_data.csv")
combdat <- read.csv(readfile)

w<-which(combdat$No_signal==1)
combdat$ftcd[w]<-9 #cases marked 9 were seen but did not have a signal

supplementary <- 0 #set this to zero for the main paper. With other values we can change the selection criteria to look at implications of using original language exclusion cutoff. When supplementary=1, we include only those shown in flowchart as group 1 (native and nonnative)

if(supplementary==1){
  mydir <- alldir[2]
  figdir <- "05.1-graphic.outputs"
}

#We will create a code that divides people into 4 groups. 
#1A are native English speakers (1)
#1B are non-native speakers who pass the preregistered exclusion criterion (2)
#2A are non-native speakers who failed the preregistered exclusion criterion, but passed the modified criterion (3)
#2B are non-native speakers who failed the modified criterion. (4)

#We first create a code that reflects whether strict exclusion criteria are met for language. This is 1 for lextale < 80, 10 for gram12err >1, and 11 if both are met
combdat$lang2exclude <- 0
w<- which(combdat$gramerr12>1)
combdat$lang2exclude[w]<-10
if(supplementary==1){
  combdat$lang2exclude <- 0
  w<- which(combdat$gramerrs>3)  #gramerrs has all items and here we use cutoff of 3
combdat$lang2exclude[w]<-10
}
w<- which(combdat$lexTALE<80)
combdat$lang2exclude[w]<-combdat$lang2exclude[w]+1
#We now use langgroup to determine specific exclusions, depending on setting of supplementary

combdat$langpreregexclude<-0
w<- which(combdat$gramerrs>3)
combdat$langpreregexclude[w]<-1

combdat$langgroup <-1
w<-intersect(which(combdat$langpreregexclude==0),which(combdat$nativeEnglish==0))
combdat$langgroup[w] <-2

w<-intersect(which(combdat$langpreregexclude==1),which(combdat$nativeEnglish==0))
combdat$langgroup[w] <-3

w<-intersect(which(combdat$lang2exclude==1),which(combdat$nativeEnglish==0))
combdat$langgroup[w] <-4


if(supplementary==1){
  w<-which(combdat$langgroup<3) #supplementary 1 includes only groups 1A and 1B
  combdat<-combdat[w,]
}

testtab <- table(combdat$Rhanded,combdat$ftcd)
colnames(testtab)<-c('-FTCD','+FTCD','no signal')
rownames(testtab)<-c('Left-handed','Right-handed')

ftcd.dat <- filter(combdat,ftcd==1) #has demog, behav and ftcd data for those who did ftcd
langtab <- table(ftcd.dat$Rhanded, ftcd.dat$langgroup)
#Langtab cells can be accessed with 3 indices corresponding to Rhanded,langexclude and native English status).

myftcd <- filter(ftcd.dat) #we'll do analysis on myftcd
#can add here criteria for exclusion


```
 


### Data Quality and Outliers for fTCD
``` {r dataqual, echo=FALSE, warning=FALSE}
#As pre-registered, we identify cases who have high values of SE for the LI, as this indicates the measurements are unusually variable from trial to trial
#We compute Qlimit based on Hoaglan-Iglewicz formula and exclude cases that exceed this value.
# Identify outliers
for (t in 1:6){
  SEcol <- which(colnames(combdat) == paste0(LETTERS[t], '_mean_se'))
  Q3<-quantile(combdat[ , SEcol],.75,na.rm=TRUE)
  Q1<-quantile(combdat[ , SEcol],.25,na.rm=TRUE)
  Qlimit<-Q3+2.2*(Q3-Q1)
  
# If there are at least 10 trials, include the data
  excludecol = which(colnames(combdat) == paste0(LETTERS[t], '_exclude'))
  trialscol = which(colnames(combdat) == paste0(LETTERS[t], '_N'))
  combdat[,excludecol] <- NA #initialise with NA
  combdat[which(combdat[ , trialscol] > 9), excludecol] <- 0
  combdat[which(combdat[ , trialscol] < 10), excludecol] <- 1
  
  # If the SE is too high, exclude the datatrials
  combdat[which(combdat[ , SEcol] > Qlimit) , excludecol] <- 1
}

# Count number of missing or excluded datapoints per task. 


# First set to NA those who did not do ftcd
n_excludeLI = matrix(data=NA, nrow=1, ncol=6)
for (t in 1:6){
  excludecol = which(colnames(combdat) == paste0(LETTERS[t], '_exclude'))
  n_excludeLI[t] = length(which(combdat[ , excludecol] > 0)) 
}

# Should any participants be excluded? If a participant has more than one excluded task, the participant is excluded entirely
combdat$DopExclude <- 0
tmp <- combdat$A_exclude + combdat$B_exclude + combdat$C_exclude + combdat$D_exclude + combdat$E_exclude + combdat$F_exclude
combdat$DopExclude[which(tmp > 1)] = 1
n_excluded = length(which(combdat$DopExclude == 1))

ddat<- filter(combdat,DopExclude==0,ftcd==1) #not really necessary to create this, but done for consistency with previous script : this has just those who did ftcd and who were not excluded on demographics or ftcd.

# We now count how many included participants omitted a single task
n_excludeLI = matrix(data=NA, nrow=1, ncol=6)
for (t in 1:6){
  excludecol = which(colnames(ddat) == paste0(LETTERS[t], '_exclude'))
  n_excludeLI[t] = length(which(ddat[ , excludecol] > 0)) 
}

```


# Abstract  

_Background_: Most people have strong left-brain lateralisation for language, with a minority showing
right- or bilateral language representation. On some receptive language tasks, however,
lateralisation appears to be reduced or absent. This contrasting pattern raises the
question of whether and how language laterality may fractionate within individuals.
Building on our prior work, we postulated (a) that there can be dissociations in
lateralisation of different components of language, and (b) these would be more common in
left handers. A subsidiary hypothesis was that laterality indices will cluster according to
how far they involve generation of words or sentences, vs receptive language. 
_Methods_: We tested these predictions in two stages: At Step 1 an online laterality battery (Dichotic listening, Rhyme Decision and Word Comprehension) was given to `r sum(testtab)` individuals (`r round(100*sum(testtab[1,]/sum(testtab),0))`% left handers); At step 2, functional Transcranial Doppler Ultrasound (fTCD) was used with `r sum(testtab[,2])` of these individuals (`r round(100*testtab[1,2]/sum(testtab[,2],0))`% left
handers), who completed three production and three receptive language tasks. 
_Results_: Neither the online nor fTCD measures supported the notion of a single language laterality factor, but nor was there evidence for the predicted two-factor structure. In general, tests of language production were left-lateralised and the receptive tasks were at best weakly left-lateralised or, in the case of Word Comprehension, slightly right-lateralised. The online measures were at best only weakly correlated with fTCD measures.  Most of the fTCD measures had split-half reliabilities of at least .7, and showed a distinctive pattern of intercorrelation, supporting a modified two-factor model in which, paths were added so that Phonological Decision (production) and Sentence Comprehension (reception) loaded on both the factors. The same factor structure fitted data from left- and right-handers, but mean scores on the two factors were lower (less left-lateralised) in left-handers. 
_Conclusions_: Factor 1 corresponds to the traditional lateralised language centre, but the nature of Factor 2 remains unclear. We propose that future fMRI studies could test whether it reflects activity in temporal lobe centres. Although these have been regarded as bilateral, based on population-based data, we suggest that they can be reliabily lateralised in individuals, but to either right or left. 

KEYWORDS: language laterality, handedness, dichotic listening, visual half-field,  
functional transcranial Doppler ultrasound  

Abbreviations: CBFV, cerebral blood flow velocity; fTCD, functional transcranial
Doppler ultrasound; LIz score, laterality index expressed as individualised z-score  

_In our Stage 1 Report (registered at https://osf.io/p8k2b) we gave the background for our preregistered hypotheses and analysis plan for this study. In the current paper, with the exception of the Abstract, material prior to Participants is the same as the wording from the Stage 1 Report, except for minor typographical changes (e.g. verb tense), and some sentences where departures to preregistration are made explicit. The latter are in italic font. Some pre-registered sections have been moved after the Results section to improve logical flow; these are shown in bold italic._

## Introduction  
Cerebral lateralisation for language has been studied both in populations and within individuals. At the population level, it is well-established that, for most people, language generation is predominantly controlled by the left hemisphere of the brain. There is individual variation, and a minority of people have right hemisphere language or do not show clear bias to one side. Numerous sources of evidence converge to show that atypical language laterality is more common in left handers (around 70% left-lateralised) than right handers (around 95% left-lateralised; Carey & Johnstone, 2014; Knecht, Deppe, Dräger, Bobe, Lohmann et al., 2000; Rasmussen & Milner, 1976, 1977; Vingerhoets, 2019). Strong left-lateralisation is not seen for all aspects of language, however. As will be reviewed below, functional brain imaging has shown that on some language tasks left-lateralisation at the population level is either reduced or absent. If we regard language lateralisation as a single dimension it may be tempting to conclude that a language task that is not strongly lateralised at the population level is likely to be a noisy or invalid measure (cf. Bethmann, Tempelmann, De Bleser, Scheich, & Brechmann, 2007, Sørensen & Westerhausen, 2020). In practice, little attention has been given to individual differences in language functions that are not strongly lateralised. Vingerhoets (2019) noted that to date few studies have distinguished between left-lateralised, right-lateralised and bilateral phenotypes within a single lateralised function, and few have compared laterality across different functions.  

Tasks that do not show a population bias to left or right may nevertheless be lateralised within individuals – but with absent or reduced population bias to left-sided functioning. For example, if we have a language task where there is a 50:50 mixture of left- and right-lateralised individuals, the population mean will indicate no lateralisation, suggesting that both hemispheres participate in the task in individuals. However, a subset of individuals may nevertheless be reliably lateralised to one side or the other, but with equal proportions being left-lateralised or right-lateralised. In that case, we should find people who have different language functions mediated by opposite hemispheres.
This notion is compatible with suggestive evidence that some people have discrepant language lateralisation for different tasks measured using fMRI (e.g. Ramsey, Sommer, Rutten, & Kahn, 2001; Lee, Swanson, Sabsevitz, Hammeke, Scott, Possing, & Binder, 2008) or for different brain regions when performing a single task (Bethmann et al., 2007). It has, however, been difficult to draw firm conclusions due to a lack of reliable and validated laterality measures and well-powered studies in this area. An additional problem is the lack of available data on individual participants in the majority of laterality studies using fMRI, electrophysiology as well as behavioural methods.  

It is important to clarify the nature of atypical lateralisation, as cerebral asymmetry has clinical implications for such issues as epilepsy surgery and recovery from aphasia, as well as informing our understanding of brain-behaviour associations, and the neurobiological basis of the human language capacity. For these reasons we have designed a multi-centre study to quantify several measures of cerebral asymmetry using behavioural and physiological measures, in a sample enriched with left-handed participants. We planned to acquire a large dataset of reliable language laterality measures, including behavioural methods and functional transcranial Doppler ultrasound (fTCD), which will be shared following the principles of open research.  

## Individual Differences in Language Lateralisation
Woodhead, Bradshaw, Wilson, Thompson and Bishop (2019) and Woodhead, Thompson, Karlsson and Bishop (2020) compared language lateralisation for a range of tasks designed to engage different aspects of language functioning. These studies used fTCD, which quantifies lateralisation by directly comparing blood flow in left and right middle cerebral arteries during performance of an activation task. A group of 31 left handers and 43 right handers performed six language tasks twice on two occasions. Tasks were selected based on the dual-stream model of Hickok and Poeppel (2007), which postulates that language functioning engages two parallel processing streams. The dorsal pathway feeds forward to the inferior frontal gyrus where phonological representations are translated into articulation and is strongly left-lateralised. The ventral pathway, involving the middle and inferior temporal gyri, maps phonological representations onto lexical conceptual representations, and is thought to have weak or absent left-sided dominance. The two streams are not independent; they are both connected to a left-lateralised combinatorial network. Woodhead et al. (2019, 2020) selected tasks involving list generation (covertly reciting overlearned sequences such as days of the week, months of the year) and phonological decision (judging if pictured words rhymed) to index dorsal stream activity. To engage the ventral pathway they selected tasks involving semantic decision (judging if pictured words belonged in the same semantic category) and syntactic judgement (judging whether a series of nonsense words such as ‘The tarben yipped a lev near the kruss’ had grammatical structure). Tests of sentence generation (covertly describing a picture) and sentence comprehension (selecting a picture to match the meaning of a spoken sentence) were predicted to involve both pathways.
Woodhead et al. (2019, 2020) found that a bifactor model did better than a single factor model at accounting for covariances between laterality indices, but the two factors did not divide neatly according to ventral/dorsal stream predictions. Contrary to prediction, the list generation task did not show high loadings on either factor, despite taxing articulatory processes, though it should be noted this task also had much lower test-retest reliability than other tasks (rs = .33). The strongest laterality was seen for the sentence generation task, which indexed the first factor. This factor had significant loadings from phonological decision, semantic decision and sentence comprehension. All of these tasks were left-lateralised overall, though to varying extents. The second factor had loadings from sentence comprehension (which was left-lateralised) and syntactic decision (which was not lateralised). The two factors were highly correlated in right handers, but in left handers they were less well correlated. The tentative interpretation of these results was that in some individuals (primarily left handers) there can be a dissociation between laterality for language generation (factor 1) and comprehension (factor 2). The pattern of results also suggested that word retrieval may be the key process characterising factor 1, rather than the articulatory aspect of speech production. It was noteworthy that the tasks loading strongly on factor 2 were the only two tasks that involved auditory presentation of stimuli.  

An important feature of the data was that test-retest reliability of the laterality index was as high for tasks that were poorly lateralised as for those that were strongly lateralised (Woodhead et al., 2019, 2020). This challenges the interpretation that these are tasks where both hemispheres are equally involved. If that were the case, the true laterality index would be zero for all people, and any individual variation would just be noise, so test-retest reliability would be low. Instead, there were stable individual differences for 'bilateral' tasks, but with equal probability of bias to left or right. This does not preclude the possibility that some people have true 'bilateral language', i.e., equal involvement of both hemispheres, but it does challenge the idea that tasks that show no bias at the population level invariably mean there is no bias in individuals. Further evidence comes from a fTCD study by Woodhead, Rutherford and Bishop (2018), which included a list generation task that was not significantly lateralised. The LI from this task was nevertheless significantly correlated with laterality indices for word and sentence generation, both of which showed the usual left-hemisphere bias. Overall, these observations suggest that there are meaningful, stable, individual differences in degree of lateralisation, even for tasks that show no bias at the population level; this is consistent with the notion that different language functions may be primarily mediated by opposite hemispheres in some individuals (Bishop, 2013).  

The primary goal of the current study is to consolidate the findings of Woodhead et al. (2019, 2020) by replicating and extending the findings of dissociated language functions, using some new tasks. We studied a large sample using online behavioural laterality assessment, plus a smaller subset of these individuals assessed with fTCD.  

## Methodological considerations  
Most contemporary studies of brain lateralisation use fMRI, which provides information about localisation as well as laterality of brain activation. Estimates of lateralisation from fMRI are dependent on the experimental task, the specific brain region, and the selection of a baseline task. Decisions about how to quantify laterality, and selection of statistical thresholds can lead to different estimates of group and individual asymmetry (Bradshaw et al., 2017; Seghier, 2008; Wilke & Lidzba, 2007). In addition, fMRI has poor temporal resolution and is expensive enough to preclude routine studies using large numbers of participants. In contrast, fTCD—the method used by Woodhead et al. (2019, 2020)—allows for direct comparison of blood flow in the left and right middle cerebral arteries, and has good temporal resolution. Although fTCD cannot provide information about which brain regions are active, it is considerably less expensive than fMRI and is portable. fTCD has also been validated using the gold standard Wada test of language lateralisation (Knecht, Deppe, Ebner, Henningsen, Huber et al., 1998). A third approach to the study of functional asymmetry, which dates back to the 1960s, involves inferring which hemisphere is more engaged in behavioural tasks when visual or auditory stimuli are presented in a way that preferentially engages one hemisphere (reviewed in Bryden, 1982). Accuracy or response time measures can be used to provide an indication of left- or right-sided bias, both at the group level and in individuals. We have recently shown that good quality data can be obtained with some behavioural tasks using online administration, which makes it feasible to assess very large samples (Parker, Woodhead, Thompson, & Bishop, 2020).  

In principal, it would be of value to use all three approaches with the same set of participants, to obtain convergent evidence from methods that make different assumptions and use different approaches to assess laterality. Ultimately, we aim to adopt that approach: here we made a start on that goal with a study of individual differences in language lateralisation that uses the last two of these methods: behavioural testing in a large sample, followed by fTCD with a subset of the same participants. We first describe the rationale for selecting specific measures: the tasks are described in greater detail under Methods.  

## Behavioural measures  

Our selection of behavioural measures was guided by methodological and theoretical considerations. In terms of methodology, we have been exploring the use of online administration for behavioural laterality tasks (Parker et al., 2020). Given our interest in exploring the nature of bilateral language, we do not regard it as important that a task shows a population bias in lateralisation, provided that test reliability is strong, indicating stable individual differences (see Positive Controls, below). From a theoretical perspective, we have a particular interest in contrasting tasks that involve language production vs receptive language, while noting that this distinction is not always clearcut, as many receptive tasks can involve covert language generation.  

One of the first behavioural tasks that was used to study language lateralisation is dichotic listening, where a person hears simultaneous streams of words or speech sounds in left and right ears. Under binaural presentation, the contralateral auditory pathways take precedence and the ipsilateral pathways are suppressed. Thus sounds presented to the right ear have a more direct access to the left hemisphere speech systems than those played to the left ear, with a strong bias to report items from the right ear being present at a population-level. Good reliability (above r = .75) was found for a dichotic listening task administered via a mobile app (Bless et al., 2013) and we found similarly high levels of reliability for this task using online presentation (Parker et al., 2020). Dichotic listening laterality is not, however, strongly predictive of language laterality as measured by fMRI (Bethmann et al., 2007; although see Sørenson & Westerhausen, 2020, for a reappraisal). This lack of specificity could mean that factors such as attentional bias affect performance, invalidating the test as a measure of language laterality, particularly in individual participants. However, another possibility is that dichotic listening is a good measure of lateralisation of receptive language, but it may be dissociable from laterality for language generation.  

Another type of behavioural method to assess lateralisation involves visual presentation. Stimuli are briefly placed in the left or right visual half-fields, which project primarily to the contralateral hemisphere. This method has long been used to assess language laterality, either using written words or pictures as stimuli (Bryden, 1982). Laterality indices show a right visual field advantage (VFA) at the population level, but results depend crucially on specific aspects of task design. Laterality indices from such tasks do not, however, necessarily correlate highly with dichotic listening (Voyer, 1998). Hunter and Brysbaert (2008) argued that one needs a visual half field task involving speech production to obtain good prediction of language laterality as measured by fMRI. This hypothesis fits with our theoretical perspective: a visual half-field task that involves language generation would be expected to be better than dichotic listening for predicting lateralisation of word generation as measured by fTCD. Van der Hagen and Brysbaert (2018) reported reliability for three visual laterality tasks in a sample of 50 left handers tested on two occasions, with test-retest correlations ranging from .49 (optimal viewing position - OVP- for written words), .77 (visual half-field with pictures) to .83 (visual half-field with words). Parker et al. (2020) developed a new rhyme decision task that involved covert naming, but reliability was below a prespecified cutoff for acceptability of .65 ($r_s = .63$). We subsequently gathered pilot data on a modified version of the task for 15 left handers and 15 right handers, and obtained split-half reliability of 0.74. Contrary to our expectation, task performance was not significantly lateralised in either left handers or right handers, but the good reliability indicates it measures a stable individual difference.  

The pilot study also gathered data on two further tasks designed to tap into more receptive aspects of language: the OVP task, and a new word comprehension task, that simply involved selecting which of two laterally-presented pictures matched a spoken word. Reliability of the OVP task was relatively poor, but the laterality index from the word comprehension task had split-half reliability of 0.74, again suggesting there are stable individual differences in lateralisation. In our pilot data, the word comprehension task was significantly lateralised, but in the opposite direction to prediction, i.e. with better performance for pictures shown in the left compared to the right visual field. Given our goal of using reliable tasks that involve production or receptive language, regardless of lateral bias shown on the tasks, we decided to focus on dichotic listening, judgement and word comprehension (see Methods). In practice, our chosen language tasks differ in ways other than the generative/receptive distinction: one visual half-field task, for instance, involves written rather than spoken language, and some tasks require accessing meaning whereas others do not. It would not be possible to design a battery that completely controlled for all task variables; rather we planned to administer tasks with diverse characteristics, predicting that generation vs reception of language will determine which laterality indices form a common factor.  

_Functional transcranial Doppler ultrasound tasks_  

The tasks included identical or closely similar versions of four of the tasks previously used by Woodhead et al. (2019, 2020), all of which had good test-retest reliability. In that study, two tasks (Sentence Generation and Phonological Decision) loaded primarily on factor 1 (language production), and two tasks (Sentence Comprehension and Syntactic Judgement) loaded primarily on factor 2 (receptive language). For each factor, one additional task was used: the gold standard Word Generation task with letter stimuli for language production (Knecht et al., 1998), and a new Word Comprehension task for receptive language. The latter task is the same as the online word comprehension task described above.  

## Positive controls   

If there are no significant correlations between different tasks it is important to demonstrate that this is not simply due to use of inadequate measures or impact of uncontrolled unwanted variables. Demonstration of good reliability of laterality indices in effect provides a positive control. Parker et al. (2020) found very weak intercorrelations between a set of online tasks, despite test-retest reliability for individual tasks of .7 or above. Woodhead et al. (2019, 2020) showed that for the six tasks used in their fTCD study, dissociations between LIs for different tasks could not be attributed to weak reliability, as all laterality indices (LIs) except list generation showed test-retest reliability (rs) of 0.6 or more). In the current study, we did not have resources to test all participants twice, but planned to repeat the online tests for a subset of 50 individuals (50% left-handers). In addition split-half reliability using alternate items was assessed for all measures.  

## Sampling approach  
One reason for uncertainty about the phenomenon of dissociated language functions is that laterality measures follow a strongly skewed distribution, and people with dissociated or atypical lateralisation are, by definition, rare (Mazoyer et al., 2014; Johnstone et al., 2020). Some researchers with an interest in atypical lateralisation have focussed exclusively on left handers, which gives a higher yield of such individuals (Van der Haegen & Brysbaert, 2018; Gerrits, Verhelst & Vingerhoets, 2020). Given our findings that handedness may influence patterns of association and dissociation of lateralised language functions, we planned to recruit both left- and right handers in a 2:1 ratio, to give adequate power to detect such differences.  

A further complication is that left handers do not form a uniform group. Over many years, various suggestions have been made about possible subdivisions between types of left handers: in particular it has been proposed that right-sided language lateralisation is associated with extreme left-handedness (Knecht et al., 2000; Mazoyer et al., 2014). Another common idea is that familial left-handedness distinguishes between subtypes of left handers, or may identify a genetic predisposition to left-handedness in right handers (McKeever & VanDeventer, 1977). This notion remains popular, although empirical support is weak (Orsini, Satz, Soper & Light, 1985). Indeed, it has been criticised for making no sense in relation to genetic models of handedness (Bishop, 1980; 1990), which attribute a relatively minor causal role to genes and a high contribution from chance factors. We did not make strong predictions about variation within left handers, but we gathered data on strength and familiality of handedness that will allow for exploratory analyses of this topic.  

We describe below the rationale for sample size determination. With online testing, we  gathered a large number of participants, which is the basis for a preliminary test of the 'dissociable language laterality' hypothesis. The initial sample was recruited according to handedness, with the goal of having 300 left handers and 150 right handers.  

In the second phase of the study, we compared findings from the online measures with those obtained using direct measures of brain lateralisation from fTCD on a subset of the initial sample. We aimed to test around half the sample on fTCD as well as online methods, as simulations indicated that a sample with 112 left handers and 112 right handers would be adequately powered to test our hypotheses (see Sampling and Analysis plan, below). Note that online test results were not used to select individuals for phase 2: the aim was to test all available participants until our quota of left- and right handers was met.  

## Research questions  

The overarching question is whether there are cross-hemispheric dissociations in lateralisation of different language functions, and if so whether there are separable dimensions of laterality for tasks that primarily implicate language generation and receptive language. A positive answer to this question would challenge the conventional conceptualisation of language lateralisation as a unitary dimension, and support instead the dissociable language laterality hypothesis.  

A subsidiary question is whether dissociation between laterality dimensions is more characteristic of left- than right-handers.  

A final question is whether online behavioural measures are comparable to direct measures of cerebral blood flow in indexing language laterality. It is generally assumed that both types of laterality measurement are indexing the same underlying bias, but the nature of what is measured is very different: facilitation of processing material on one side for behavioural measures, and lateralised increase in blood flow through the middle cerebral artery in the other.  

## Hypotheses and predictions  
_Online behavioural measures_  

1. It is predicted that the pattern of correlation between laterality indices from online measures will reflect the extent to which they involve language generation, rather than whether they involve spoken or written language. Thus we anticipated dissociation between the Rhyme Decision task, which requires covert speech production, and the Word Comprehension task and Dichotic Listening tasks, which do not. We further anticipated that dissociations between tasks are not accountable for in terms of low reliability of measures – i.e. correlations of laterality indices between tasks will be lower than split-half reliability of the measures.  

_FTCD measures_  
2. The same hypothesis predicts that the fTCD data will fit a model where 'language generation' tasks cluster together on one factor, and 'receptive' language tasks on a second factor. The factors will be correlated, but the fit of a two-factor model will be superior to a single-factor model.  
3. From our hypothesis that handedness affects language laterality, following Woodhead et al. (2020), we predicted that better model fit will be obtained when different parameters are estimated for left- vs right handers, compared with when all parameters are equated for the two handedness groups.  
4. The same hypothesis leads to the further prediction that on categorical analysis, individuals who depart from left-brained laterality on one or more tasks will be more likely to be left-handed than those who are consistently left-lateralised.  

_Relationship between fTCD and behavioural laterality indices_  
5. Our predictions depend on online and fTCD measures indexing the same lateralisation processes. On this basis we predict that the laterality profile obtained with the online language battery will be significantly associated with the profile seen with the direct measurement of cerebral blood flow using fTCD, with laterality on dichotic listening and word comprehension relating more strongly to receptive language tasks, and rhyme decision to language generation tasks.  

# Methods  
## Criteria for participants  
Our original stage 1 flowchart for participant recruitment is now presented as Figure `r fignumber+2` below, showing both the original planned sample size and the obtained sample size. 

The inclusion criteria were as follows:  
● Aged 16-50 years. The younger age limit avoids developmental change in language skills affecting performance, and the upper limit makes it less likely that bone density will make it difficult to find a Doppler signal.  
● Normal or corrected-to-normal vision and normal hearing  
● Native English proficiency  
● Access to a laptop or desktop computer with stereo headphones for use in the online   testing. N.B. it is not possible to do the online tests on a tablet or phone.  
The exclusion criteria are as follows:  
● A history of psychiatric or neurological illness  
● A history of developmental language disorder, dyslexia or autism.  
● A history of dyspraxia  
● Unwillingness to travel to one of the testing sites for step 2 of the study  
● Contraindications or unwillingness to participate in fMRI in future parts of the study. 


The initial screening questionnaire was administered on the Gorilla platform (www.gorilla.sc; Anwyl-Irvine, Massonnié, Flitton, Kirkham & Evershed, 2020), and is provided in Appendix 1. Note that we did not exclude those who speak more than one language, provided they meet our stringent criteria for native-level competence in English (see below). We also gathered information on bilingualism/multilingualism in the initial demographic questionnaire, so it would be possible to determine if this had any impact on results. Participants were told that this test was part of a multistage study and they might be invited back for in-person testing. Although there was no obligation on them to do so, if they were in principle willing, they had the opportunity to provide contact details.  

Although this study did not include fMRI, we prioritised participants who were likely to be eligible for fMRI in a future phase of the research. The initial screening questionnaire checked whether participants were in principle willing to return for an MRI scan, and whether they were aware of any contraindications to being scanned.  

If the participant passed the screening questionnaire, they were invited to complete an online consent form prior to starting the online testing session. Those who took part in the second session (in-person testing with fTCD) completed an additional written consent form for that session.  

## Procedure
There were two stages to the project. All participants proceeded beyond the initial screening  completed the online testing, and a subset of participants were invited back for the second session (fTCD). Participants received course credit or were paid in accordance with guidelines at their local testing centre, at a rate that was at least level with the UK minimum wage.  

## Step 1: Online testing  
After passing the screening questions and completing an online consent form, participants continued with the online testing via the Gorilla platform (www.gorilla.sc; Anwyl-Irvin et al., 2020). In this session participants completed the following (described in more detail below):  
● Demographics questionnaire  
● Edinburgh Handedness Inventory (Oldfield, 1971)  
● A test of ocular dominance and footedness  
● Measures of language proficiency.  
● Tests of language laterality  
  -  Rhyme Decision  
   - Word Comprehension  
   - Dichotic Listening
    
Many of these tests have been reported previously, and have been made available for reuse: https://gorilla.sc/openmaterials/104636.  

### Demographics Questionnaire  
The demographics questionnaire is shown in Appendix 2. Participants were asked to report age, gender, years in education, and whether they were bilingual. They were also asked about their own hand and foot preference, and left-handedness in first degree relatives (parents and siblings - see Appendix 2, question 7). The latter information was used to compute a proportional familial sinistrality index (Corey & Foundas, 2005).  

### Edinburgh Handedness Inventory  
Participants completed the Edinburgh Handedness Inventory (Appendix 3; Oldfield, 1971) in order to quantify handedness on a continuum. For 10 activities, participants indicated their hand preference on a 5-point scale (right hand strongly preferred, right hand preferred, no preference, left hand preferred, left hand strongly preferred). This questionnaire was selected for compatibility with prior studies relating language laterality to hand preference.  

### Test of Ocular Dominance  
A version of the Porta test (Porac & Coren, 1976) that is suitable for online testing was administered to determine each participant’s eye dominance in central gaze (i.e., when looking straight ahead). This test classifies participants as being either left or right eye dominant.  

### LexTALE  
The Lexical Test for Advanced Learners of English (LexTALE; Lemhöfer & Broersma, 2012) was used to assess level of English vocabulary knowledge. Participants judge the lexical status of 60 letter strings (word or non-word). Forty are real English words and 20 are non-words. To correct for the unequal proportion of words and non-words, LexTALE scores are calculated as ((number of words correct/40 x 100) + (number of nonwords correct/20 x 100))/2). _With hindsight, our preregistration was unclear in stating "following the norms provided by Lemhöfer & Broersma, those scoring below 80 would not be eligible for inclusion in the online testing or fTCD". In practice, we applied this criterion only to those who did not have English as a first language, as it had been our intent to use the test to exclude non-native speakers with inadequate English competence (see above re inclusion of non-native speakers)._  

### Games With Words test  
The Games With Words test (Hartshorne, Tenenbaum, & Pinker, 2018) was used to screen participants for adequate understanding of English grammar. The first 8 items involve participants reading a sentence, such as “the dog was chased by the cat”, and deciding which of two pictures presented below the text matches the sentence. The two pictures in this example include a dog chasing a cat and a cat chasing a dog. Items 9-35 were four-alternative forced choice questions where participants select which of four sentences sounds most natural: e.g., (1) “what age are you?”, (2) “How age are you?”, (3) “How old are you?”, and (d) “what old are you?”. _Our preregistration stated that to be included as having native English speaker proficiency, participants needed to make no more than 3 errors on this test on the basis that Hartshorne et al. (2018) reported that most monolingual English-speakers performed close to ceiling and very few made more than 3 errors.  In practice we found a many non-native speakers exceeded this cutoff, but so too did a large number of native English speakers. Accordingly we did further analysis using the original dataset provided by Hartshorne et al, and found that we had misinterpreted their account, and that it was common to find native speakers who made more than 3 errors on the original Games with Words items, making our original criterion for native speaker competence indefensible. Bishop (2022) identified a subset of 12 items where native English speakers from the Hartshorne et al sample made very few errors and proposed a new cutoff on this subset (more than one error) for excluding non-native speakers with poor English competence. This new test set and cutoffs were substituted in the current study for the preregistered criteria (see below)._

### Rhyme Decision  
A modified version of a rhyme decision visual half-field task reported by Parker et al. (2020) was administered to determine brain lateralisation for language production. This involved participants judging which of two parafoveal images rhymed with a foveally presented word. The laterality index from the original task had test-retest reliability of r = .63, and the overall lateralisation effect, though significant, was small. We modified the task from the original with the aim of improving its psychometric properties: first, we removed trials in which neither of the pictures rhymed with the target word, as these were potentially confusing. Second, we increased the distance between the centrally presented word and parafoveal images, to ensure the image is projected exclusively, at least initially, to the contralateral hemisphere. Pilot testing with 30 participants obtained split-half reliability of r= .74 with this version. _Note, however, lower reliability was found with our main sample, as reported in Results_.  
_Materials_. Written stimuli consisted of twenty-six monosyllabic written words (e.g. bite). Stimulus pairs were created so that each written word was paired with an image with a name that rhymed (e.g. kite). For each of the 26 word-image pairs there was a corresponding pair whose words did not rhyme with the first pair (e.g. the corresponding pair for bite-kite was more-door), see Appendix 3. On each trial, stimuli were presented such that the written word was accompanied by one rhyming image and one non-rhyming image (e.g. kite-bite-door). All possible combinations were included such that each pairing constituted four individual items. Thus, there were 52 unique stimuli, and all images appeared both as rhymes and non-rhymes (see Parker et al., 2020, for further detail).  
Word stimuli were presented in 28 pt black Courier New font on a white background. The images were displaced at 7.9 degrees of visual angle from the point of fixation. Gorilla’s screen scaling tool was used to maintain consistency of stimulus size across browsers and computers.  
_Procedure_. Participants completed a familiarisation procedure where they viewed each image pair. The images were shown with their name presented in text below the image to ensure that participants used the appropriate word when making a rhyme decision. They then completed 208 trials of the rhyme decision task (four blocks of 52 stimuli). Each trial began with a central fixation cross which was visible for 800 ms after which a foveally presented word appeared for 200 ms. Two bilateral images then appeared for 150 ms. At stimulus offset, participants indicated whether the centrally presented word rhymed with the image present to the left or right visual field by pressing S for the left visual field and K for the right visual field. Participants’ responses triggered the next trial. Accuracy and response times were recorded.   

### Word comprehension task  
A novel online word comprehension task was administered to determine brain lateralisation of receptive language. This task involved indicating which of two semantically related parafoveal images matched an orally presented word stimulus. Pilot testing with 30 participants and one block of stimuli obtained split-half reliability of r = .76.  _Note, however, lower reliability was found with the four-block version of the task used here in our main sample, as reported in Results_.  

_Materials_. A total of 108 experimental images were selected from the MultiPic databank (Duñabeitia et al., 2018). As Duñabeitia et al. had participants name stimuli, we were able to select images where at least 50% of English participants generated the intended name; M= 90.1%, SD= 13.06. The names of the images were high frequency according to Zipf scores from the SUBTLEX-UK database (Van Heuven, Mandera, Keuleers, & Brysbart, 2014); M = 4.4, SD = 0.41, minimum = 3.8. Each image was paired with another to form a semantically related pair, amounting to 54 pairs (see Appendix 4). Latent semantic analysis ratings were acquired using the LSA CU Boulder web-interface (http://lsa.colorado.edu/). LSA scores ranged from 0.26 to 0.87; M = 0.46, SD = 0.87. We aimed to avoid errors arising from visual confusion between pictures, and to this end, nine raters rated the pairs of images for visual similarity on a 5 point scale (1: very similar to 5: not all similar). Generally, images pairs were rated as being visually distinct; M = 4.13, SD = 0.47. Audio files of the spoken name for each picture were created using Google cloud text-to-speech (https://cloud.google.com/text-to-speech), using a male, British voice.  

Each image pair was presented a total of four times, with each image twice in either the left or right visual field. The name of each image was presented twice: once when the image was in the right visual field, and once when the image was in the left. `r fignumber <- fignumber+1`See Figure `r fignumber` for an example. The images were displaced at 7.9 degrees of visual angle from the point of fixation. Gorilla’s screen scaling tool was used to maintain consistency of stimulus size across browsers and computers. In total, 208 trials were presented across four blocks.  

![Figure `r fignumber`: A schematic illustration of a trial on the word comprehension task. First, participants are presented with a fixation cross for 600 ms. A word, in this case envelope, is presented aurally, along with two semantically related parafoveal images that are visible for 150 ms. Participants then indicate which of the two images matched the word. In this case participants would indicate that the word matched the image on the left](WordCompDemo.jpg) 

_Procedure_. Participants completed a familiarisation procedure (where each picture was shown along with its spoken name) and a number of practice trials. They then completed 208 experimental trials (four blocks of 52 stimuli). Each trial began with a central fixation cross which was visible for 600 ms. The target word was then presented aurally along with two semantically related parafoveal images that were visible for 150 ms. Participants indicated whether the oral word matched the image in the left or right visual field by pressing Q for the left visual field and P for the right visual field. Participants’ responses triggered the next trial. Accuracy and response times were recorded.  

### Dichotic Listening Task  
An online dichotic listening task was administered to assess the lateralisation of speech perception (Hugdhal & Andersson, 1986). On each trial, participants heard two consonant-vowel (CV) auditory stimuli simultaneously to each ear. The stimuli have previously been administered online via an app (Bless et al., 2013) and Gorilla (Parker et al., 2020) and the task has good test-retest reliability (r = .78).  

_Materials_. Six stop-consonants (/b/, /d/, /g/, /p/, /t/, /k/) were combined with the vowel /a/ to create consonant-vowel stimuli. Stimuli are paired in all possible combinations and played in each sound channel (e.g. /pa/-/ga/). This resulted in 36 unique pairings (including pairs with the same sound repeated).
_Procedure_. To ensure adequate headphone use, participants were screened on two measures. The first, described by Woods, Siegel, Traer, and McDermott (2017), involves participants deciding which of three pure tones is the quietest. One of the three tones is played 180 degrees out of phase, so this task is difficult to perform through speakers but relatively easy with headphones. The second task was a stereo check developed by Parker et al. (2020). This task involves participants listening to a sound played in a single channel and reporting whether the sound was played to the left or the right ear via a button press. Each task had six trials. We excluded participants who scored less than 4 correct on each.  

Participants completed three blocks of the dichotic listening task. This amounted to 96 trials when excluding homonyms. Our decision to use three blocks was based on the previous observation that there is not much improvement in reliability after 85 trials when using the dichotic listening task (Parker et al., 2020). Each trial began with a fixation cross, which was presented for 250 ms. Participants then heard the sound pairs and reported the syllable that they heard. If they heard two different syllables, participants were instructed to report the sound that they heard the most clearly. Responses were made by clicking a button which corresponded to one syllable. The response triggered the start of the next trial. The side of selected response and response times was recorded. Errors can occur on this task if the participant selects a syllable that was not presented to either ear: these were rare, but were recorded and were used to exclude those who perform poorly.  

### General Procedure  
The study implemented a within subjects design where participants completed all online tasks. When completing the battery, participants were instructed to sit approximately 50 cm from the screen. Participants completed four blocks of the rhyme decision (A) and word comprehension tasks (B; 52 trials each). They completed three blocks of the dichotic listening (C; 36 trials each). Blocks of different tasks were interspersed in a quasi-random order (i.e. ABC, BAC, CAB). Other online tasks relating to different studies were interspersed to avoid boredom and maximise efficiency of data collection.

## Step 2: Functional Transcranial Doppler ultrasound (fTCD)  
A subset of participants were given six tasks using fTCD that could be administered in a single session of about 90-120 mins. These participants were selected on the basis of handedness and willingness and ability to travel for in-person testing to one of the five test centres.  
The tasks were designed to cover a range of language functions in as standard a format as possible. Four of the language tasks (tasks B, C, E and F below) were based on tasks used by Woodhead et al. (2019). We omitted the List Generation task used by Woodhead et al. (2019), as it showed poor test-retest reliability. Instead, we used a shortened version of the gold standard Word Generation task (Knecht et al., 2000). The basic procedure for this task was the same as used by Knecht et al., but with fewer trials and a shorter rest period between trials. The sixth task was a new Word Comprehension task, selected to act as a third indicator of receptive language.  
The total battery consisted of the following tests:  
_A. Word Generation_. On each trial, the task was to silently generate words that begin with a specified letter, and subsequently report them when a cue is given. The task used 18 letters that commonly begin English words (S, C, P, D, T, B, R, A, E, F, G, H, I, L, M, U, O, W).  

_B. Sentence Generation_. This task was based on Mazoyer et al. (2014). Participants were shown a line drawing in each trial and asked to produce a meaningful sentence to describe it. The 18 stimuli were selected from those used by Woodhead et al. (2018).  

_C. Phonological Decision_. Following a familiarisation task, for each trial, participants decided whether the names of pairs of pictures rhymed. The design of the original task from Woodhead et al. (2019) was supplemented by adding a number of black and white drawings from the MultiPic database (Duñabeitia et al., 2018), in order to create stimuli for three new trials.  
_D. Word Comprehension_. Participants were presented with pairs of pictured items on each trial, and were asked to press a key to indicate which one matched a spoken word. The pictures were from the same semantic category. The picture pairs and audio stimuli for this task were the same as those used in the online word comprehension task (see below for further details).   
_E. Sentence Comprehension_. Two pictures were presented on each trial, and the task was to determine which one matched a spoken sentence. Items were based on picture pairs taken from the Test for Reception of Grammar - 2 (Bishop, 2003), using distractors that differed in syntactic arrangement of words. As we used slightly more trials than Woodhead et al. (2019), additional pictures and sentences were devised in the same way. New spoken sentences were created for all items using Google text to speech, with a male British voice.  
_F. Syntactic Decision_. On each trial, participants were presented with a sequence of words and non-words, and asked to judge if they formed a plausible ‘jabberwocky’ sentence with correct syntactic structure. Simultaneous spoken and written presentation was used. The stimuli used by Woodhead et al. (2019) were supplemented with additional ‘Jabberwocky’ stimuli from Fedorenko et al. (2010).  

`r fignumber <- fignumber+1`
Timings for the tasks are shown in Figure `r fignumber`. All stimulus materials for the tasks are available on OSF: (https://osf.io/g3qms/?view_only=a6c36957ffba4bc39232d9265ea13dd8). We previously used 15 trials of each task but increased this to 18 trials for the current study, to ensure that there were sufficient stimuli for reliable estimation of a laterality index, even if some trials are lost due to recording problems. Previously we presented tasks with an inter-stimulus interval (ISI) of 33 seconds (including 20 s of the task and 10 s of rest). We increased this by extending the rest period to 15 s. Hence, the ISI was 38 seconds and each task lasted 11 minutes 24 seconds in total. The overall testing time (excluding set-up, practice trials and breaks) was 68 minutes 24 seconds.  

Task order was counterbalanced between participants to avoid order effects using a replicated Latin square design using a customised script in R Studio. Details of task A are described by Woodhead et al. (2018), and Tasks B, C, E and F by Woodhead et al. (2019). Task D has been designed for this study and is described below.  

![Figure `r fignumber`: Timings within a single trial for the six tasks used with fTCD](tasktimings.jpg) 

Task D (Word Comprehension) used the same 54 picture pairs and audio stimuli that were used for the online Word Comprehension task. The procedure for this task in fTCD has been designed to match that of the Sentence Comprehension task (task E). In each epoch, a pair of drawings was presented for 3.33 seconds, one above the other, and the spoken word for one of the drawings was played. Participants were required to respond by button press to indicate which drawing matched the spoken word. Each pair of drawings was presented twice, with a different drawing used as the target word, creating 108 epochs in total. Epochs were presented in a pseudorandomised order, with no repetitions of a drawing pair in successive epochs. The same order was used for all participants. The target location was pseudorandomised so that the target was presented at the top / bottom of the screen (and therefore eliciting a left / right button press) in 50% of all epochs to avoid a response bias. In each fTCD trial, six epochs (drawing pairs) were presented, each lasting 3.33 seconds. The pseudorandom order was designed so that within an fTCD trial, there were equal numbers of top or bottom targets. This ensured that odd-even split half reliability data would not be affected by trial-to-trial variation in which hand is used. Participants were instructed to respond as quickly and accurately as possible.  

## Computing laterality index from online battery tasks  
The Edinburgh Handedness Inventory was scored in the standard way, reflecting how often the left / right hands were used across all the items in the inventory. This score was converted into an index as described below. Indices greater than 0 were categorised as right-handed, and indices less than 0 as left-handed. The Porta Test classifies participants as being either left or right eye dominant.  
For the Rhyme Decision and Word Comprehension tasks, each participant’s RT for correct trials was used to calculate a laterality index that corresponds to a z-score, known as a LIz score. This can be readily derived from a t-test conducted on each participant's individual data, where accurate log response times (after outlier exclusion) are the dependent variable and visual field is the independent variable (see Parker et al., 2020). This estimates sensitivity to stimuli presented in either visual field and act as a laterality index. The LIz score is very highly correlated with the more traditional Laterality Index, computed as (L-R)/(L+R), but it allows one to identify participants who show a statistically significant RT advantage for one side, i.e. where the LIz on a 2-sided test has p < .05.  
For dichotic listening, a laterality index was calculated based on trials in which participants correctly identified one of the two consonant-vowel sounds. The count of correct responses that corresponded to each side was used to generate an accuracy laterality index. The index was calculated in the traditional fashion: 100*(Left – Right) / (Left + Right). The laterality index will allow us to relate our findings to prior research that uses this index. In addition, we computed a LIz-score for each participant, using the formula:  
z = (pL-.5)/sqrt((pL*pR)/n)  
where pR is the proportion of R responses, pL is proportion of L responses, and n is total L and R responses. As with the rhyme decision task, the z-score is highly correlated with the traditional laterality index, but has the advantage that it can be used to test whether an individual’s lateral bias is unlikely to have arisen by chance.  

## Computing laterality index from raw fTCD data  
Following Woodhead et al. (2019) we calculated a laterality index using a customised R script (R Core Team, 2016). The cerebral blood flow velocity (CBFV) data were first down-sampled from 100 to 25 Hz and then segmented into epochs. Spiking or dropout data-points were identified as being outside of the 0.0001–0.9999 quantiles of the CBFV data. If only a single artefact data-point was identified within an epoch, it was replaced with the mean for that epoch. If more than one data-point was identified, the epoch was rejected. The CBFV wss then normalised (by dividing by the mean and multiplying by 100) such that the values for CBFV become independent of the angle of insonation and the diameter of the middle cerebral artery. Heart cycle integration was then used to normalize the data relative to rhythmic modulations in CBFV. 
_The pre-registration document stated that "Epochs are baseline corrected using the interval from −10 to 0 s pre-stimulus time (where the onset of the ‘Clear’ stimulus is used as the start of the trial, 0 s pre-stimulus time)." This was an error, as we had intended to replicate the timings used by Woodhead et al (2021). The interval from -10 to 0 is non-optimal because it includes activity from the previous trial, and for this reason Woodhead et al used a shorter interval of -5 to 2 seconds for baseline correction. For consistency between studies, and to avoid unstable baselines, this shorter baseline period was also used here._  
 Finally, artefacts were identified as values below 60% and above 140% of the mean normalised CBFV—any epochs containing such artefacts are rejected. The laterality index was then computed as the mean difference between blood flow velocity in left and right channels over a period of interest that is specified in advance for each task. For tasks without an overt speech ‘report’ stimulus (tasks C-F), the period of interest was from 6-23 s peri-stimulus time to cover the whole period where the participant is performing the decision task; left-hemisphere blood flow typically increases as each item in the trial is responded to. For tasks with a ‘report’ stimulus (tasks A-B) the period of interest was from 6-17 s to avoid capturing activity related to the overt speech production.
The standard error of the laterality index for each individual was computed from the laterality index obtained across individual trials, and was used both to identify outliers (individuals with unreliable laterality indices) and to categorise individuals in terms of direction of laterality. When the 95% confidence interval of the laterality index spanned zero, laterality was coded as bilateral; otherwise, it was coded as left or right depending on the sign of the difference.  
In the previous study by Woodhead et al. (2019) we excluded cases with fewer than 12 acceptable trials and then used the Hoaglin-Iglewicz (1987) criterion for outlier detection: this involves identifying cases that have values well outside the interquartile range for the group. This was used to identify individuals where the laterality index for a given task had an unusually large standard error, indicative of high trial-by-trial variation. However, we noted that some individuals had very low standard errors, despite having fewer than 12 usable trials, and so in the current study we changed the requirement for a minimum number of trials to 10 (out of 18 trials administered), while retaining the Hoaglin-Iglewicz method for removing data for a given subject and condition when the standard error of the laterality index was high.  

## Sampling and Analysis Plan
The analysis starts with presentation of descriptive data, including distributions of scores by handedness, and split-half reliability of measures. The hypotheses are then tested, following the preregistration from table 1 of our original Stage 1 report. The preregistered text is presented with each analysis. All analyses are conducted with alpha = .02 and power .9. A Rmarkdown script to run analyses on simulated data is available on Open Science Framework: https://osf.io/9dbrg/?view_only=357994fa8f6b49ee83964f5108d82ee2.


  

## Participants
  
`r fignumber<-fignumber+1`

![Participant recruitment flowchart](COLAflow.png)

_Departures from pre-registration plan_  
Our plan had been to recruit 300 left-handers and 150 right-handers for the online behavioural battery, and from these to select 112 left-handers and 112 right-handers for in-person testing.  Because of the Covid situation, the time periods when it was possible to test in person were greatly restricted, and testing had to be carried out under strict conditions to ensure safety (researchers wearing full personal protective equipment in a ventilated space, and cleaning of equipment between participants). Furthermore, researchers and participants could become unavailable for testing at short notice because of a positive Covid test or notification of a contact with an infected person, and some participants were understandably reluctant to come for in-person testing.

The disruption due to these factors meant we did not meet our target numbers for in-person testing, despite over-recruiting for online testing. We decided to relax the criteria for language competence of participants, as we felt it was uncertain whether this would make any difference to laterality indices; rather than excluding potential participants, it seemed preferable to include at Step 2 any participant who had completed Step 1 and was willing to come for testing, and then check retrospectively to see whether inclusion of these participants had any impact on the results. Analyses that apply cutoffs to exclude participants on the basis of language test scores are provided in Supplementary materials. Differences in means, variances and covariances for the full sample and the restricted sample are all very small and there are no meaningful differences to results from statistical tests or modeling. 


Figure `r fignumber` presents the original preregistered recruitment flowchart modified to show actual numbers recruited. In total we tested `r testtab[1,2] + testtab[1,1]` left-handers, `r testtab[1,2]` of whom were tested with fTCD, and `r testtab[2,2] + testtab[2,1]` right-handers, `r testtab[2,2]` of whom were tested with fTCD. 

Figure `r fignumber` divides participants according to the language screen. Group 1 corresponds to cases who meet preregistered criteria: they are either native English speakers, or non-native speakers who passed the pre-registered criterion for language competence (LexTALE of 80 or more, and no more than 3 errors on full Games with Words test). Group 2 is subdivided into subgroup (a), who failed the original Games with Words criterion, but passed the revised criterion, and subgroup (b), who failed the screen using the new, shorter test (making more than 1 error). Here we report data on the whole sample with no exclusions based on the language screen, but in Supplementary material we compare our results with those obtained using the original, stringent language cutoff (excluding all Group 2), or a revised cutoff (excluding only Group 2b).


![Participant recruitment flowchart: preregistered (planned) and actual numbers](COLAflow.jpg)

<!--- can't get script to recognise COLAflow.Tried with both jpg and png, and in different directories--->


 


### Demographic data 

```{r demog.table,echo=F}
#We'll use the table1 package to create a nice-looking summary table for demographics; this excludes those excluded on language tests, but otherwise includes everyone given the online testing.

mycomb <- combdat #this is a hangover from previuos - we now exclude by langgroup early on in the script, so combdat has correct people excluded on Lextale or Grammar task

mycomb$Gender <- factor(mycomb$male,levels=c(0,1),labels=c("Female","Male"))
label(mycomb$age) <- "Age (yr)"
mycomb$Native <- factor(mycomb$nativeEnglish,levels=c(0,1),labels=c("No","Yes"))
label(mycomb$Native)<-"Native English speaker"
mycomb$Bilingual <- factor(mycomb$bilingual,levels=c("No","Yes"),labels=c("No","Yes"))
mycomb$Handedness <- factor(mycomb$Rhanded,levels=c(0,1),labels=c("Left-Handed","Right-Handed"))
mycomb$ftcd <- factor(mycomb$ftcd,levels=c(0,1),labels=c("No FTCD data","With FTCD data"))

demog.table <- table1(~ Gender + age + Native+ Bilingual+EHI.LI|(factor(ftcd)+Handedness) , data=mycomb,overall=F)
ftab <- t1flex(demog.table) #convert from table1 to flextable format to allow formatting of width etc
ftab <- fontsize(ftab,size=10)
ftab<- fit_to_width(ftab,8)
ftab
tabnumber<-tabnumber+1
```
Table `r tabnumber`: _Demographic characteristics of sample_

Table `r tabnumber` shows demographic data for the subset of individuals tested on the online battery only, and the subset who also completed the session with FTCD. It is evident from inspection that there are no systematic differences between the two subgroups. 

## Subsample for test-retest study_ 

```{r test-retest, echo=F}
#need to read in sess1 and sess3 for the test-retest data

sess1 <- read.csv(paste0(alldir[1],'/02-data/02.1_gorilla/sess1.csv'))
sess3 <- read.csv(paste0(alldir[1],'/02-data/02.1_gorilla/sess3.csv'))
mtab<-table(sess3$male,sess3$Rhanded)

# Calculate delay between session 1 and session 3 for retest participants
for (i in 1:length(sess3$ID)){
  sess3$date_S1 <- sess1$date[which(sess1$ID == sess3$ID)]
}

# Reformat dates
sess3$date <- as.Date(sess3$date, format='%d/%m/%Y')
sess3$date_S1 <- as.Date(sess3$date_S1, format='%d/%m/%Y')
sess3$date_diff <- difftime(sess3$date, sess3$date_S1)

date_diff_stats <- fivenum(sess3$date_diff)

```

A subsample of `r nrow(sess3)` participants was retested on part of the online battery within `r ceiling(as.numeric(date_diff_stats[5]) / 7)` weeks of the first session (median = `r date_diff_stats[3]` days, range = `r date_diff_stats[1]` to `r date_diff_stats[5]` days). There were `r mtab[1,1]` left-handed females, `r mtab[2,1]` left-handed males, `r mtab[1,2]` right-handed females, and `r mtab[2,2]` right-handed males. The retest session included the Rhyme Decision and Word Comprehension tasks, which were new, but not Dichotic Listening, for which we had adequate evidence of test-retest reliability from the previous study by Parker et al (2021). 


## Online behavioural battery  

### Derivation of laterality indices  

```{r dichotic.plot,echo=F}


mycomb$DLsig <-0
w<-which(abs(mycomb$DL.zlat)>1.96)
mycomb$DLsig[w]<-1


DLdat <- mycomb[mycomb$excludeDL==0,]
DLsides <- ggplot(DLdat, aes(x=DL.L, y=DL.R, color=Handedness,shape=as.factor(DLsig))) +
  xlab("N correct L ear")+
   ylab("N correct R ear")+
  geom_point()+
  ggtitle("Dichotic Listening") +
  scale_shape_manual(name="Significantly lateralised",
                     labels=c("No","Yes"),
                     values=c(4,16))+
  scale_color_manual(name="Handedness",
                       labels=c("Left","Right"),
                       values=c("blue","red"))+
  geom_abline(intercept = 0, slope = 1)

ggsave(paste0(mydir,"/03-graphic-outputs/AFig1_DLsides.png"),width = 6, height = 4)




```



```{r RDT,echo=F}
mycomb$RDTsig <-0
w<-which(abs(mycomb$RDT.zlat)>1.96)
mycomb$RDTsig[w]<-1


RDTdat <- mycomb[mycomb$excludeRDT==0,]
RDTsides <- ggplot(RDTdat, aes(x=RDT.Lmean, y=RDT.Rmean, color=Handedness,shape=as.factor(RDTsig))) +
  xlab("Mean correct RT (ms) left VHF")+
   ylab("Mean correct RT (ms) right VHF")+
  geom_point()+
  ggtitle("Rhyme Decision") +
  scale_shape_manual(name="Significantly lateralised",
                     labels=c("No","Yes"),
                     values=c(4,16))+
  scale_color_manual(name="Handedness",
                       labels=c("Left","Right"),
                       values=c("blue","red"))+
  geom_abline(intercept = 0, slope = 1)

ggsave(paste0(mydir,"/",figdir,"/AFig2_RDTsides.png"),width = 6, height = 4)


```


```{r WC,echo=F}
mycomb$WCsig <-0
w<-which(abs(mycomb$WC.zlat)>1.96)
mycomb$WCsig[w]<-1


WCdat <- mycomb[mycomb$excludeWC==0,]
WCsides <- ggplot(WCdat, aes(x=WC.Lmean, y=WC.Rmean, color=Handedness,shape=as.factor(WCsig))) +
  xlab("Mean correct RT (ms) left VHF")+
   ylab("Mean correct RT (ms) right VHF")+
  geom_point()+
  ggtitle("Word Comprehension") +
  scale_shape_manual(name="Significantly lateralised",
                     labels=c("No","Yes"),
                     values=c(4,16))+
  scale_color_manual(name="Handedness",
                       labels=c("Left","Right"),
                       values=c("blue","red"))+
  geom_abline(intercept = 0, slope = 1)

ggsave(paste0(mydir,"/",figdir,"/AFig3_WCsides.png"),width = 6, height = 4)

#plot with all 3 L vs R scatterplots together in a row.
allplot <- ggarrange(DLsides, RDTsides, WCsides, ncol = 3, nrow = 1,common.legend=TRUE)


ggsave(paste0(mydir,"/",figdir,"/allLRbeh.png"),width = 9, height = 3)
#also save to current project to enable access when knitting to word
ggsave("allLRbeh.png",width = 9, height = 3)
fignumber<-fignumber+1

```

![Responses to stimuli on left and right: online laterality tasks_](allLRbeh.png)
  

Visualisations of the raw data from which laterality indices were computed, colour-coded by handedness, are shown for the three behavioural tasks in Figure `r fignumber`. The point type indicates whether the absolute individual z-lat score was greater than 1.96, indicating reliable lateralisation for that individual. Note that on the Dichotic Listening task there is inevitably a negative correlation between these totals, because on each trial the response is either left or right: hence, the more responses are 'left' the fewer are 'right', and vice versa. The black line shows the point of equality, where the number correct is the same for left and right. For this task, the points are distinguished for those where the proportion on one side is significantly different from .5 (filled circles), versus those who are equally likely to respond to L or R (crosses, which are bunched around the black line). It is evident from this plot that a high proportion of participants are significantly lateralised, and that overall the sample shows a right ear advantage, i.e. there are more points above the black line than below it. 

In our pre-registration we stated that we would compute a conventional laterality index, 100* (Left-Right)/(Left+Right), as well as a laterality z-score:
(pL-.5)/sqrt(pL*pR/n).  We made one small modification, which was to flip the sign of these quotients, so that for all our laterality measures, left-hemisphere superiority is reflected in a positive score. This has no material effect on any computations, but gives better consistency with other research. For the laterality z-score, scores were censored at +/- 10, to avoid undue influence from a handful of extreme scores (participants who responded overwhelmingly to one ear).  


As is evident from Supplementary figure `r suppfignumber+1`, the LIz score is very highly correlated with the conventional LI, the principal difference being that the LIz follows the normal distribution, with a sigmoid shape at the extremes (truncated in the Figure because of the censored scale). For subsequent analyses, we use LIz, as this allows us to compare different tasks on a common scale. 

In Rhyme Decision, the task was to judge which of two pictured items had a name that rhymed with a centrally-presented written word. The pictures were presented in the left or right periphery. This was an easy task, as the words used were common, and the participants were given a practice session where they were introduced to all the pictures and their names. We could therefore use accuracy as an index of engagement with the task, and we excluded `r length(intersect(which(combdat$excludeRDT==1),which(combdat$lang2exclude==0)))` participants with accuracy of less than 75% correct. 

The dependent variable of interest was Response Time (RT), which was computed for correct responses in each half-field, after excluding outliers using a participant-specific algorithm. This involved taking the complete set of correct RTs for a participant, and applying the Hoaglin-Iglewicz (1987) criterion of outlier detection with cutoff set to 1.65 to remove unusually long RTs. In addition, any RTs less than 200 ms were excluded. A LIz was then computed by computing a t-test for each participant, to compare the mean correct RT to left- and right-sided stimuli. Absolute values of LIz greater than 1.96 can be regarded as evidence that an individual is significantly faster to one side than the other. Because RT is scaled so that high values correspond to poor performance, the LIz was computed so that it was positive when left-sided RT was greater than right-sided RT. Thus those with a left-hemisphere advantage should cluster below the black line.


As with Rhyme Decision, Word Comprehension involved responding to laterally presented visual stimuli. The stimuli are pictures of semantically-related words, and the task is simply to respond to the picture whose name is spoken. Again, this is an easy task, where the focus is on RT of correct responses. Participants who made more than 75% errors on the task (N = `r length(intersect(which(combdat$excludeWC==1),which(combdat$lang2exclude==0)))`) were excluded from analysis.  The same method as for Rhyme Decision was used to remove outlier RTs participant by participant before computing a LIz based on comparison of mean RT to left and right sides, where a positive value indicated faster RTs to stimuli presented in the right visual field.  


```{r DLdensities,echo=F,include=F}


plot1 <- ggplot(DLdat, aes(x = DL.LI, y = DL.zlat)) + 
  geom_point(shape = 4,  size = 1)+
  ggtitle("Dichotic Listening") 

  

dens1 <- ggplot(DLdat, aes(x = DL.LI, fill = Handedness)) + 
  geom_density(alpha = 0.4) + 
  geom_vline(xintercept = 0, linetype="dotted")+
  theme_void() + 
  theme(legend.position = "none")

dens2 <- ggplot(DLdat, aes(x = DL.zlat, fill = Handedness)) + 
  geom_density(alpha = 0.4) + 
  geom_vline(xintercept = 0, linetype="dotted")+
  theme_void() + 
  theme(legend.position = "none") + 
  coord_flip()

dens1 + plot_spacer() + plot1 + dens2 + 
  plot_layout(ncol = 2, nrow = 2, widths = c(4, 1), heights = c(1, 4))

DLdens <- ggsave(paste0(mydir,"/",figdir,"/AFig4_DLdens.png"),width = 5, height = 4)
ggsave("AFig4_DLdens.png",width = 5, height = 4)#resave to project folder

suppfignumber<- suppfignumber+1
```







## Online battery: Distribution of Laterality indices  

Before testing specific predictions about interrelationships between measures, we conducted preliminary analysis on LIz values for all three online tasks, to test for normality, to check for significant lateralisation in left- and right-handers, to compare laterality between handedness groups, and to compute split-half and test-retest reliability for laterality indices.  


```{r DL-ttests,echo=F, message=F, warning=F}
#Make a table to show characteristics of different tests

onlinesummary <- data.frame(matrix(NA,nrow=12,ncol=4))
colnames(onlinesummary)<-c('Statistic','Dichotic','Rhyme','Comprehension')
onlinesummary[,1]<-c('N','Mean (SD)','Skew','Kurtosis','Shapiro-Wilk normality','Mean (SD) L-hander','Mean (SD) R-hander','one-group t L-hander','one-group t R-hander','R-hander vs L-hander t','Split half r','Test-retest r (N = 53)')
```


```{r fillonlinesummary,echo=F, message=F, warning=F}



mytask<-'DL'
writecolnum <- 2 #column of online summary to write to for this task
onlinesummary <- populate(mycomb,mytask,onlinesummary,writecolnum,'beh')

mytask<-'RDT'
writecolnum <- 3 #column of online summary to write to for this task
onlinesummary <- populate(mycomb,mytask,onlinesummary,writecolnum,'beh')
onlinesummary[12,3]<-round(cor(sess1$RDT.zlat,sess3$RDT.zlat,use='complete.obs'),3)

mytask<-'WC'
writecolnum <- 4 #column of online summary to write to for this task
onlinesummary <- populate(mycomb,mytask,onlinesummary,writecolnum,'beh')
onlinesummary[12,4]<-round(cor(sess1$WC.zlat,sess3$WC.zlat,use='complete.obs'),3)


ft<-flextable(onlinesummary)
ft<-autofit(ft)
ft
tabnumber <- tabnumber+1
```

Table `r tabnumber`: _Descriptive statistics for three online laterality measures_  


```{r behpirates, echo=FALSE, warning=FALSE,message=F}
#NB Formatting of this figure needs to be tweaked to achieve good resolution and legibility, but we can do that when we know what format figures need to be created in. 


 mypath<-paste0(mydir,"/",figdir)
  plotname<-paste0(mypath,'/beh_pirates.jpg')
#  plotname<-'beh_pirates.jpg' #creating a version in project directory
jpeg(plotname, width = 800, height = 500)

bLIdat <- combdat %>% 
  dplyr::select(ID, Rhanded, DL.zlat,RDT.zlat,WC.zlat)
colnames(bLIdat) <- c('ID','Handed','Dichotic','Rhyme','Comprehension')

bLIdat$Handed <- as.factor(bLIdat$Handed)
levels(bLIdat$Handed)<-c("L","R")
longdata.b <- pivot_longer(data = bLIdat, cols = c(3:5), names_to = 'Task', values_to = 'LI')
longdata.b$Task<-as.factor(longdata.b$Task)
longdata.b$Task <- factor(longdata.b$Task, levels = c('Dichotic', 'Rhyme', 'Comprehension'))
pirateplot(data = longdata.b, LI ~ Handed * Task)
abline(h=0)

title(main=paste0('Distributions of LIz \non behavioural tasks; N = ',length(bLIdat$ID)))

fignumber<-fignumber+1

```


![Pirate plot distributions of LIz scores on online tasks](beh_pirates.jpg)  



As shown in Figure `r fignumber` and Table `r tabnumber`, distributions of LIz on the three tasks were non-normal, and the three tasks showed very different patterns of laterality. As expected from previous studies, on dichotic listening there was a clear right ear advantage in both left- and right-handers. In addition, there was a small but statistically reliable difference between handedness groups, with stronger laterality in the R handers.  We did not assess test-retest reliability for this task, as we had done this in our previous study with this task and found it to be high. Here we confirm excellent split-half reliability for this task. 



The Rhyme Decision task was far less reliable, with split half reliability of .432 and test-retest reliability of .539.  These figures indicate that laterality on this test is far from being at chance, but there is a great deal of random variation. In addition, although the task showed statistically reliable laterality in both left- and right-handers in this large sample, the effect size was small, and most individuals were not significantly lateralised. Furthermore, there was no effect of handedness on laterality on this task.  

The Word Comprehension task did rather better in terms of reliability, with split half reliability of .664, though test-retest reliability was lower at .555. The striking observation about this task was that it showed a laterality bias in the opposite direction to what is usually seen in language tasks, with faster responses to pictures viewed in the left visual half-field, which projects directly to the right hemisphere. Furthermore, there was a significant effect of handedness, with the laterality index being more negative in left-handers than in right-handers.  


## Testing a two-factor model using behavioural data

Prediction 1 stated: _The pattern of correlation between laterality indices from online measures will reflect the extent to which they involve implicit speech production, rather than whether they involve spoken or written language. Thus we anticipate dissociation between the rhyme judgement task and the other two measures (dichotic listening and word comprehension task), which is not accountable for in terms of low reliability of measures._  

We had planned to do a formal comparison of model fit using AIC weights, but we realised our data were inadequate for this because our Model A was, in formal terms, just-identified: it simply estimated three pairwise correlations from the data, and always gave perfect fit, regardless of the size or direction of correlations. We considered alternative approaches to the analysis, but decided to just report the correlations at this stage, as the pattern of results was distinctive, and we had already planned to incorporate the online behavioural measures into the SEM analysis that includes the fTCD measures (see section x below).  




```{r behavcorrs,echo=F,warning=F,include=F}


bivdat <- filter(mycomb,excludeRDT==0,excludeDL==0,excludeWC==0)
#Assign Group at random
set.seed(50) #make reproducible
bivdat$Group<-1+rbinom(nrow(bivdat),1,.5)
#Check handedness distribution
handgrouptab <- table(bivdat$Handed,bivdat$Group) #This is just to confirm roughly equal distribution of L and R handers in the 2 random groups.


#tempx and tempy are reassigned to variables of interest before calling generic function that will base plot on these two variables
bivdat$tempx <- bivdat$DL.zlat
bivdat$tempy <- bivdat$RDT.zlat
name1 <-"Dichotic Listening z-lat"
name2 <- "Rhyme decision z-lat"
DL_RD_plot <- bivplot2(bivdat,name1,name2) #this is our specially created function
#I've commented out saving the individual plots, just because I've used ggarange to make a composite plot with all 3 pairings
#ggsave(paste0(mydir,"/03-graphic-outputs/DL-RDT.png"),width = 6, height = 4)

bivdat$tempy <- bivdat$WC.zlat
name2 <- "Word Comprehension z-lat"
DL_WC_plot <- bivplot2(bivdat,name1,name2)
#ggsave(paste0(mydir,"/03-graphic-outputs/DL-WC.png"),width = 6, height = 4)

bivdat$tempx <- bivdat$RDT.zlat
name1 <- "Rhyme Decision z-lat"
RD_WC_plot <- bivplot2(bivdat,name1,name2)
#ggsave(paste0(mydir,"/03-graphic-outputs/RD-WC.png"),width = 6, height = 4)

#For now am making a plot with all 3 scatterplots together in a row. Easy to change layout if needed.
allplot <- ggarrange(DL_RD_plot, DL_WC_plot, RD_WC_plot, ncol = 3, nrow = 1,common.legend=TRUE)
ggsave(paste0(mydir,"/",figdir,"allbiv.png"),width = 9, height = 3)
#ggsave('allbiv.png',width = 9, height = 3)
fignumber<-fignumber+1
```
![Bivariate distributions of LIs on behavioural tasks](allbiv.png) 

Figure `r fignumber` shows scatterplots of the bivariate relationships between the three variables. It is evident from inspection that we can reject model C, in which all three LIs are independent, and model B1, where only Dichotic Listening and Rhyme Decision are correlated. The strongest correlation is between the two visual tasks, Rhyme Decision and Word Comprehension, as predicted by model B2. 

Note that correlations will be influenced by test reliability. Indeed, the correlation between Rhyme Decision and Word Comprehension is close in magnitude to the split half reliability of the two measures. An estimate of the association between these measures after adjusting for the split-half reliabilities can be obtained using the Spearman-Brown correction for attentuation, r.xy(corrected) = r.xy(observed)/sqrt(r.xx * r.yy), which gives a value of `r round(.44/sqrt(.436*.664),3)`.


## Functional Transcranial Doppler (fTCD) measures



We excluded `r n_excluded` participants who met our criteria for outliers on two or more fTCD tasks. For the remaining `r nrow(ddat)` participants, the numbers with missing data on the six tasks (A = Word Generation, B = Sentence Generation, C = Phonological Decision, D = Word Comprehension, E = Sentence Comprehension and F = Syntactic Decision) were `r n_excludeLI[1]`, `r n_excludeLI[2]`, `r n_excludeLI[3]`, `r n_excludeLI[4]`, `r n_excludeLI[5]` and `r n_excludeLI[6]` respectively.

### Time course of left and right cerebral blood flow velocity for the fTCD tasks  

`r fignumber <- fignumber+1`
![Timecourse of left and right blood flow velocity (left axis) and L-R difference + 100 (right axis) for six tasks in left- and right-handers)](alltimecourse.png)

Figure `r fignumber` shows the mean time course of blood flow velocity on left and right channels for left- and right-handers. In addition, the difference between left and right channels is plotted in black, after adding 100 to the values so that they can be shown on the same plot (true scale is on right hand axis). The laterality index is computed as the mean difference score (shown in black) over the period of interest. For Word Generation and Sentence Generation tasks, the LI is computed during a period corresponding to silent generation; the waveform peaks again after this period, corresponding to the activity from the subsequent spoken response. For the other tasks, a series of items is presented in each trial and no spoken response is required. The periodic fluctuations in the response correspond to the individual items that are responded to.  

Inspection of this figure indicates that we see a strong left hemisphere bias in both handedness groups for Word Generation, Sentence Generation and Phonological Decision, whereas the other tasks do not show this pattern.   


<!--- Need to decide on colour scheme and stick to it-->
```{r selectplots,echo=F, warning=F,message=F}
tasknames <- c('Word generation','Sentence generation','Phonological decision','Word comprehension','Sentence comprehension','Syntactic decision')
ddat$Handed<-as.factor(ddat$Rhanded)
levels(ddat$Handed)<-c("Left","Right")
for (i in 1:length(tasknames)){
  col1<- paste0(LETTERS[i],"_mean_odd")
  col2<- paste0(LETTERS[i],"_mean_even")
  col3 <-paste0(LETTERS[i],"_mean_LI")
  c1<-which(colnames(ddat)==col1)
  c2<-which(colnames(ddat)==col2)
  c3<-which(colnames(ddat)==col3)
  h <- which(colnames(ddat)=='Handed')
  
  myfile <- ddat[,c(h,c1,c2,c3)]
  mycolnames <- c('Odd','Even','All')
  myrange=c(-5,6)
  p2<-doscatterplus(myfile,tasknames[i],mycolnames,myrange)
  p2
   mypath<-paste0(mydir,"/",figdir)
  plotname<-paste0(mypath,'/OddEven_',LETTERS[i],'.png')
  ggsave(plotname,p2,width = 5, height = 4)

}
#THESE PLOTS NOT CURRENTLY USED
```

## LI Summary Statistics

```{r LIpirates, echo=FALSE, warning=FALSE,message=F}
#NB Formatting of this figure needs to be tweaked to achieve good resolution and legibility, but we can do that when we know what format figures need to be created in. 
#NOW REORDERED IN TERMS OF BIAS TO LEFT HEMISPHERE

#Make task names that will print on 2 lines for compactness
tasknames2 <- c("Sentence\ngeneration","Word\ngeneration","Phonological\ndecision","Sentence\ncomprehension","Syntactic\ndecision","Word\ncomprehension")
#Now make text locations for these on pirate plot: we'll place A-C below plot and D-F above it
horizpts<-rep(1,6)
for (i in 1:6){
  horizpts[i] <- 1+(i-1)*3
}
vertpts <- rep(-5.5,6)
vertpts[4:6]<-6

 mypath<-paste0(mydir,"/",figdir)
  plotname<-paste0(mypath,'/ftcd_pirates.jpg')
 # plotname<-'ftcd_pirates.jpg' #comment out for creating file in Dropbox
jpeg(plotname, width = 800, height = 500)

LIdata <- ddat %>% 
  dplyr::select(ID, Rhanded, B_mean_LI,A_mean_LI,  C_mean_LI, E_mean_LI, F_mean_LI, D_mean_LI)
colnames(LIdata) <- c('ID','Handed','1B','2A','3C','4E','5F','6D')
LIdata$Handed <- as.factor(LIdata$Handed)
levels(LIdata$Handed)<-c("L","R")


longdata.d <- pivot_longer(data = LIdata, cols = c(3:8), names_to = 'Task', values_to = 'LI')
longdata.d$Task <- as.factor(longdata.d$Task)
levels(longdata.d$Task)<-c('B','A','C','E','F','D')
pirateplot(data = longdata.d, LI ~ Handed * Task,ylim=c(-6,8))
abline(h=0)

for (i in 1:6){
  text(horizpts[i], vertpts[i], tasknames2[i], #add label for task
     cex = 1)
}
#title(main=paste0('Distributions of LI Data \nN = ',length(LIdata$ID)))

fignumber<-fignumber+1
piratenumber <- fignumber
```
![Distributions of fTCD LIs on six tasks for 104 left-handers and 91 right-handers ](ftcd_pirates.jpg)


```{r doppler-ttests,echo=F}
#Make a table to show characteristics of different tests


ftcdsummary <- data.frame(matrix(NA,nrow=11,ncol=7))
colnames(ftcdsummary)<-c('Statistic',LETTERS[1:6])
ftcdsummary[,1]<-c('N','Mean (SD)','Skew','Kurtosis','Shapiro-Wilk normality','Mean (SD) L-hander','Mean (SD) R-hander','one-group t L-hander','one-group t R-hander','R-hander vs L-hander t','Split half r')
```

```{r fill-ftcdsummary, echo=FALSE, warning=FALSE,message=F}
#We use the same function 'populate' to populate the data frame as we had for behavioural tasks - the 'ftcd' term at end of function call ensures correct columns are found
for (t in 1:6){
mytask<-LETTERS[t]
writecolnum <- 1+t #column of online summary to write to for this task

ftcdsummary <- populate(ddat,mytask,ftcdsummary,writecolnum,'ftcd')
#ftcdsummary <- ftcdsummary[1:(nrow(ftcdsummary)-1),]
}
ft<-flextable(ftcdsummary)
ft <- fontsize(ft, size = 10)
ft<-fit_to_width(ft,8,inc=1L)
ft
tabnumber<-tabnumber+1
```

Table `r tabnumber`: _Descriptive statistics for six fTCD laterality measures_  


The pirate plot in Figure `r fignumber` shows LI values for the six tasks (A = Word Generation, B = Sentence Generation, C = Phonological Decision, D = Word Comprehension, E = Sentence Comprehension and F = Syntactic Decision) for left and right handed participants. 

Table `r tabnumber` shows basic statistics for the fTCD laterality indices, in the same format as for the online tasks. Right-handers showed significant left-lateralisation on Word Generation, Sentence Generation, Phonological Decision, and Sentence Comprehension, but were not lateralised for Word Comprehension or Syntactic Decision.  Left-handers were significantly left-lateralised for Word Generation, Sentence Generation and Phonological Decision, were not lateralised for Sentence Comprehension or Syntactic Decision, and were significantly right-lateralised for Word Comprehension.  The direct comparison between left- and right-handers showed significantly greater left-lateralisation on all tasks except Word Comprehension and Syntactic Decision, which showed only a trend in that direction.

All tasks had split half reliability coefficients of .74 or above, except for Word Comprehension, where the coefficient was only .61.

Shapiro Wilk tests revealed significant non-normality for Sentence Generation, Phonological Decision, Word Comprehension and Sentence Comprehension, though values of skewness and kurtosis were generally not extreme.

As noted above, there were a few participants with missing data on a single measure. Before running the SEM analysis, the _mice_ package @vanbuuren2011 was run in R to impute these missing values. 


```{r imputemissing,echo=F, include=F}
nunames<- c('A_P1','B_P2','C_P3','D_R1','E_R2','F_R3') #cols for SEM; short names useful here. These cols with have imputed values

thisdat <- ddat[,c('A_mean_LI','B_mean_LI','C_mean_LI','D_mean_LI','E_mean_LI','F_mean_LI')]

#Interpolate missing values using mice package
thisdat.i <- mice(thisdat, m=1, maxit = 50, method = 'pmm', seed = 500,print=FALSE)
ddati <-cbind(ddat[,c('ID','male','Handed')],complete(thisdat.i,1))
colnames(ddati)<-c('ID','male','Handed',nunames)

```






## Prediction 2: Testing a two-factor model using fTCD data

Our second preregistered prediction was: _The data will fit a model where 'language generation' tasks cluster together on one factor, and 'receptive language’ tasks on a second factor._   It was further predicted that factors will be correlated, but the fit of a 2-factor model will be superior to a single-factor model where all LIs load on a common factor.
 
The analysis conducted by Woodhead et al (2019, 2020) used an exploratory bifactor model in which each task could load on each of two factors. Because there were two measures for each task (from test and retest sessions), this exploratory approach was adequately powered. In the current study, some of the tasks were different, and we only had one measurement occasion for each of the six measures. Accordingly we used confirmatory factor analysis, using a prespecified two-factor model that constrains which indicators can load on two factors. This was compared to a unitary model, in which all tasks load on a single factor.  

`r fignumber <- fignumber+1`Figure `r fignumber` shows the pattern of correlations between LIs for the different tasks as a heat map. The two-factor model predicts that correlations will form two clusters, with positive correlations within tests A-C, and within tests D-F, but weaker or absent correlations across these two clusters of measures. The heatmap shows moderate correlations within both clusters of measures, and generally lower correlations across clusters, but there are some exceptions. Notably, there is a moderate correlation between task C (Phonological Decision) and task E (Sentence Comprehension), which is not predicted by the two-factor model. 


```{r modelfit,echo=F,include=F}

#nb we will use the variables from ddati
set.seed(50)

ddati$randgroup<-1+rbinom(nrow(ddati),1,.5) #create random group 1 or 2 for later split

#Add correlation matrix

LIcols <- c("A_P1","B_P2","C_P3","D_R1","E_R2","F_R3")

myheatmap <- makeheatmap(ddati,LIcols)

#Saved heatmap needs a bit of tweaking! Size of axis labels and grey background need fixing
ggsave(paste0(mydir,"/",figdir,"/ftcd-heatmap.png"),width = 6, height = 6)
ggsave("ftcd-heatmap.png",width = 6, height = 6)


```
![Heatmap showing correlations between laterality indices from six fTCD tasks](ftcd-heatmap.png) 

__Note from DB: NEXT SECTION is a bit of a placeholder for now. Difficult to keep it brief but have information information__

### Summary of the Structural equation modeling approach  
Because Structural equation modeling (SEM) is not widely used in laterality research, we provide here a brief explanation, to aid interpretation of the subsequent analysis.  

Structural equation modeling (Kline, 2011) is a method that allows a formal test of adequacy of competing models for explaining patterns of association between variables. The underlying assumption of this approach is that observed variables can be treated as indicators of underlying, unobserved latent variables. `r fignumber<-fignumber+1`Figure `r fignumber` shows the single factor model on the left, and a two-factor model on the right. The latent factors are shown in ovals, and the observed variables in boxes. Single-headed arrows indicate causal paths, and double-headed arrows indicate variances. Although means can be incorporated in SEM (and we shall be doing this in our analysis), the main use of SEM is to analyse patterns of covariances. The important point to note is that the path diagrams shown in Figure 1x have a precise mathematical interpretation, and can be converted into linear equations that specify the covariances between observed variables. Thus it is possible to obtain a measure of goodness of fit for observed data in relation to a model by comparing whether the observed covariances agree with those predicted by the model. We can already see by inspecting the heatmap of Figure `r fignumber-1` that a single-factor model is unlikely to provide a good fit to the observed data, because it would not predict the clustering of correlations that is evident. 

<!---Diagram could be done better!  This version assembled in ppt to get 2 models side by side--->
![One-factor vs two-factor structural equation model](path_diags_asppt.jpg)

SEM does not arrive at a single algebraic estimation of model fit, but rather uses a maximum likelihood approach, whereby values for the paths from the factors to the observed variables are first assigned starting values, and the expected covariances between variables are computed with these values, and then compared to observed covariances. This process is iterated many times with different path estimates, with an algorithm adjusting paths on each run to reduce the mismatch between observed and expected covariances. 

It may be noted that the path diagrams shown in Figure `r fignumber` include one path to each factor shown as a dotted line. This is a fixed parameter, set to 1, which is used to scale the estimates. All the other paths are free to vary, and the estimation process will consider different values, to converge on a solution that gives the best fit. Some paths may have little impact on the solution, and may be dropped without any deterioration of fit. 

There is no single method for evaluating the fit of a model to observed data. A chi square test can given an estimate of the extent of departure of a observed values from expectation: a good model is one where chi square is small and has a high associated p-value, indicating that any difference between expectation and observation is likely to just reflect sampling error. However, it is usually possible to improve fit by including additional paths or factors in a model until good fit is achieved, but this does not mean that the model is better: the goal is rather to obtain a parsimonious and theoretically meaningful model that does not include arbitrary parameters that are specified solely to fit the data. Where models are 'nested', with a more complex model including all the parameters of a base model, then model fit can be compared by subtraction of the chi square and degrees of freedom for the two models; the difference in chi square is then evaluated, and can indicate whether the simpler model gives as good a fit as a complex model with more parameters - in which case the simpler model is preferred.

Other indices have been developed that penalise models with a large number of parameters. The Comparative Fit Index (CFI) measures relative improvement of fit of a model relative to a model that assumes independence of all variables. CFI values of .95 or more are conventionally regarded as indicating acceptable fit. Another measure is the Root Mean Square Error of Approximation (RMSEA) is a 'badness of fit' measure, where a value of zero indicates good fit, and values below .05 are widely regarded as indicating acceptable fit. We report here values for chi square, CFI and RMSEA. 
 


```{r initialisebigsummary,echo=F,include=F}
#Initialise a table to show factors loadings and some other stuff (CFA, rmsea) for each model in a column, so we can compare them
bigsummary <- data.frame(matrix(NA,nrow=18,ncol=4))
colnames(bigsummary)<-c('Estimate','Model.1F','Model.2F','Model.2Fn')
bigsummary[,1]<-c('NObs','A -> Fac1','B -> Fac1','C -> Fac1','D -> Fac1','E -> Fac1','F -> Fac1','A -> Fac2','B -> Fac2','C -> Fac2','D -> Fac2','E -> Fac2','F -> Fac2','Fac1~~Fac2','CFI','rmsea','chisq','DF')
```





```{r factormodels,echo=F,include=F, warning=F,message=F}
#In lavaan, we first define the factor model between quotes
#So this step doesn't do anything - just sets up the model to be run later

#This is definition of single factor model we will use here. A_P1 will be index variable with path of 1. 
model.1F <- 'f1 =~  A_P1 + B_P2  + C_P3 +D_R1 + E_R2 + F_R3' 


#2 factor production/reception model
model.2F <- '
f1 =~  A_P1 + B_P2+C_P3
f2 =~ F_R3 + D_R1 + E_R2  #2 factor model: 
#covariance unspecified, which means there is no constraint on covariance

'


fit1 <- cfa(model.1F, estimator="WLSMV",data=ddati) #runs the model and saves results in fit1
sfit1 <- makeSEMtab(fit1) #saves the results from the model in a neat format
bigsummary<- addmodel(bigsummary,fit1,NA,'Model.1F',writecol=2) #summary from this model written to col 2 of bigsummary. For single factor model we don't specify a comparison model, hence NA.

#lavResiduals(fit1) #if we want to understand reasons for poor fit, we can look at residuals - shows size of covariances that aren't explained by model.

#Creates a structural diagram for single factor model: nb does NOT include path estimates (these can be shown if we put 'par' rather than 'diagram', but it gets messy, and the parameters are shown instead in a table)
#lots of details of this here
#https://www.rdocumentation.org/packages/semPlot/versions/1.1.2/topics/semPaths

pathfigname<-paste0(mydir,"/",figdir,"/pathfigF1")
semPaths(fit1, "diagram", weighted = FALSE,  shapeMan = "rectangle", sizeMan = 8, 
    sizeMan2 = 5,filetype='jpg',filename=pathfigname,width=3,height=2) #draws a path diagram

fit2 <- cfa(model.2F, estimator="WLSMV",data=ddati)
sfit2 <- makeSEMtab(fit2)
bigsummary<- addmodel(bigsummary,fit2,fit1,'Model.2F',writecol=3) #summary from this model written to col 3 of bigsummary

#lavResiduals(fit2)
pathfigname<-paste0(mydir,"/",figdir,"/pathfigF2")
semPaths(fit2, "diagram", weighted = FALSE,  shapeMan = "rectangle", sizeMan = 8, 
    sizeMan2 = 5,filetype='jpg',filename=pathfigname,width=3,height=2) #draws a path diagram
#anova(fit1,fit2) #compares model fit -if significant, means 2nd model is better fit than 1st. This information is now included in bigsummary.


#I checked whether the one-factor model would fit better if we specified a 2-group solution with handedness groups; it did not
#measurementInvariance(model=model.1F,estimator="WLSMV",data=ddati,group="Handed")
#CFI very low.

#Also true with the 2F model: fit is better but still well below acceptable on CFI and RMSEA/ Also gives negative variance estimates.
#measurementInvariance(model=model.2F,estimator="WLSMV",data=ddati,group="Handed")

```


```{r newmodel,echo=F,include=F}


#make oddeven file so can try same model as Woodhead et al
wantcols <- c("ID","male","Rhanded","A_mean_odd","A_mean_even","B_mean_odd","B_mean_even","C_mean_odd","C_mean_even","D_mean_odd","D_mean_even","E_mean_odd","E_mean_even","F_mean_odd","F_mean_even","DopExclude")
ddat_OE <- combdat[combdat$ftcd==1,wantcols]
ddat_OE<-ddat_OE[ddat_OE$DopExclude==0,]

#impute missing values using mice package
nunames<-wantcols[4:15]
thisdat.j <- mice(ddat_OE[,nunames], m=1, maxit = 50, method = 'pmm', seed = 500,print=FALSE)
ddat_OE <-cbind(ddat_OE[,1:3],complete(thisdat.j,1))

colnames(ddat_OE)<-c("ID","male","Rhanded","A_o","A_e","B_o","B_e","C_o","C_e","D_o","D_e","E_o","E_e","F_o","F_e")
set.seed(50)

#We explore for best model using just half the data (randgroup = 1)

ddat_OE$randgroup<-1+rbinom(nrow(ddat_OE),1,.5) #create random group 1 or 2 for later split
mygroup <-1
mydat<- ddat_OE[ddat_OE$randgroup==mygroup,]

#Model that is same as Woodhead et al
model.2FZW <- '
f1 =~  1*B_o+equal("f1=~B_o")*B_e+  #same path value for B_o and B_e
       a*A_o+a*A_e +
       c*C_o+c*C_e+
       d*D_o+d*D_e+
       e*E_o+e*E_e+
       f*F_o+f*F_e
f2 =~  NA*D_o+equal("f2=~D_o")*D_e+ #same path value for D_o and D_e
       e2*E_o+e2*E_e+
       f2*F_o+f2*F_e+
       a2*A_o+a2*A_e +
       c2*C_o+c2*C_e  #only B is omitted from f2

f2~~1*f2
A_o~~av*A_o #equate variances for odds and evens
A_e~~av*A_e
B_o~~bv*B_o
B_e~~bv*B_e
C_o~~cv*C_o
C_e~~cv*C_e
D_o~~dv*D_o
D_e~~dv*D_e
E_o~~ev*E_o
E_e~~ev*E_e
F_o~~fv*F_o
F_e~~fv*F_e
'

fit.2FZW.1 <- cfa(model.2FZW,estimator="WLSMV", data=mydat)
wantfits <- c('CFI','rmsea','chisq','df')
fitmeasures(fit.2FZW.1,wantfits)
#This gives matrix not positive definite

#Paths suggest dropping nonsig paths from f1 to D and F 
# and A from F2 (B is already missing as was excluded from model)
model.2FZWa <- '
f1 =~  NA*B_o+equal("f1=~B_o")*B_e+
       a*A_o+a*A_e +
       c*C_o+c*C_e+
       e*E_o+e*E_e
f2 =~  NA*D_o+equal("f2=~D_o")*D_e+ 
       c*C_o+c*C_e+
       e2*E_o+e2*E_e+
       f2*F_o+f2*F_e
f1~~1*f1
f2~~1*f2
A_o~~av*A_o #equate variances for odds and evens
A_e~~av*A_e
B_o~~bv*B_o
B_e~~bv*B_e
C_o~~cv*C_o
C_e~~cv*C_e
D_o~~dv*D_o
D_e~~dv*D_e
E_o~~ev*E_o
E_e~~ev*E_e
F_o~~fv*F_o
F_e~~fv*F_e
'

fit.2FZWa.1 <- cfa(model.2FZWa,estimator="WLSMV", data=mydat)

wantfits <- c('CFI','rmsea','chisq','df')
fitmeasures(fit.2FZWa.1,wantfits)
#Converges nicely


#Now test model with hold-out group 2
mygroup <-2
mydat<- ddat_OE[ddat_OE$randgroup==mygroup,]
fit.2FZWa.2 <- cfa(model.2FZWa,estimator="WLSMV", data=mydat)

wantfits <- c('CFI','rmsea','chisq','df')
fitmeasures(fit.2FZWa.2,wantfits)
```


```{r new2factor-with-all,echo=F,include=F}


mydat<- ddati #back to full LI scores and full group
model.2Fn <- '
f1 =~  B_P2+A_P1 +C_P3+ E_R2
f2 =~  NA*F_R3 + C_P3+D_R1+ E_R2   #2 factor model:

f2~~1*f2
'

fit.2F<-cfa(model.2F, estimator="WLSMV",data=mydat)
fit.2Fn <- cfa(model.2Fn, estimator="WLSMV",data=mydat)
tab.2Fn <- makeSEMtab(fit.2Fn)
fitmeasures(fit.2Fn,wantfits)

bigsummary<- addmodel(bigsummary,fit.2Fn ,fit.2F,'Model.2Fn',writecol=4) #summary from this model written to col 4 of bigsummary 
anova(fit.2Fn,fit.2F)



pathfigname<-paste0(mydir,"/",figdir,"/pathfigF2_revised")

semPaths(fit.2Fn, "diagram", weighted = FALSE,  shapeMan = "rectangle", sizeMan = 8, 
    sizeMan2 = 5,filetype='jpg',filename=pathfigname,width=3,height=2) #draws a path diagram

#redo with save to current directory
pathfigname<-"pathfigF2_revised"
semPaths(fit.2Fn, "diagram", weighted = FALSE,  shapeMan = "rectangle", sizeMan = 8, 
    sizeMan2 = 5,filetype='jpg',filename=pathfigname,width=3,height=2) #draws a path diagram

#look at residuals for diagnostics
res<-resid(fit.2Fn, type = "cor") #large abs values (> .1) indicate relationships not well accounted for


#Can't get 2nd col to reformat - need to convert to character - then OK
#bigsummary[,2]<-as.character(bigsummary[,2])
flextable(bigsummary)
tabnumber<-tabnumber+1
fignumber<-fignumber+1


```
Table `r tabnumber`: _Path estimates and fit statistics for 1-factor, 2-factor and modified 2-factor models_

```{r formatbigsummary,echo=F}
bigsummary[,2:4]<-round(bigsummary[,2:4],2)
ftb<-flextable(bigsummary)

ftb<-autofit(ftb)
ftb

```


We used the lavaan() package to perform the pre-registered model comparison. To take into account non-normality of some variables, the WLSMV estimator was specified; this uses weighted least squares with robust standard errors and a mean- and variance adjusted test statistic, and makes no distributional assumptions about the observed variables. Table `r tabnumber` summarises the main output of the model-fitting. The fit of both the one-factor and the two-factor model is poor. 

Therefore, as planned we divided the sample into two random subsamples, 1 and 2. The first subsample was used in an exploratory analysis, based on that used by Woodhead et al (2021). Fuller details of the analysis are given in Supplementary material.  Because we had data from a single session, we used the LIs from the odd and even trials to give two indicators per task. We started with a model with two factors, where all 12 measures (2 measures from 6 tasks) were allowed to load on both factors, except for Sentence Generation. This was an indicator variable with a loading of 1 on Factor 1, and no loading on Factor 2. To ensure model identification, the variance of Factor 1 was free to vary, and variance of Factor 2 was set to 1. Although this model converged with good fit, there were warnings indicating problems with unfeasibly small eigenvalues. However, when non-significant paths were dropped from the model (from Word Comprehension and Syntactic Decision to Factor 1, and from Word Generation to Factor 2), there was good model convergence with plausible parameters and excellent fit (CFI = 1 and RMSEA = 0). This same model was then evaluated with the hold-out sample, and again the fit was excellent. We therefore took this model forward to the next stage of analysis, first checking the fit with the original full sample and with the original LIs based on all trials. The path diagram is shown in Figure `r fignumber` and summary output is shown in Table `r tabnumber`;  the fit was a significant improvement on the fit of the original 2-factor model. 

![Factor structure of best-fitting model.](pathfigF2_revised.jpg)

```{r makefacscatter,echo=F,include=F}
myscatter <- function(myx,myy,xlabel,ylabel,thisdat){
thisscatter<-ggplot(thisdat, aes(x = myx, y = myy,color=Handed)) + 
  geom_point(shape = 4,  size = 1)+
 scale_color_manual(name="Handedness",
                       labels=c("Left","Right"),
                       values=c("blue","red"))+
    xlab(xlabel)+
    ylab(ylabel)+
  geom_hline(yintercept=0, linetype="dashed")+
    geom_vline(xintercept=0, linetype="dashed")
 #NB scale of factors is NOT centred on LI of zero!
  return(thisscatter)
}

```


```{r plotfacs, echo=F,include=F}
#Creates a plot and saves it; also adds factor scores to ddati
ddati <- makefactorplot(cfa(model.2Fn, estimator="WLSMV",data=ddati),'fit.2Fn',ddati)


```




## Model equivalence for left- and right-handers  
The third prediction was: _better model fit will be obtained when different parameters are estimated for left- vs right handers, compared with when all parameters are equated for the two handedness groups._ 


<!---Level of measurement equivalency are assessed through model fit of a series of nested multiple group models.  
Substantial decrease in goodness of fit indicates non-invariance
Xu: It is a good practice to look at several model fit indices rather than relying on a single one
• Δχ2
• ΔRMSEA
• ΔCFI
• ΔTLI
• ΔBIC
• ΔAIC  


Step 1: Configural invariance
  Same factor structure in each group
  First, fit model separately in each group
  Second, fit model in multiple group but let all parameters vary freely in each group
  No latent mean difference is estimated
  
  
Step 2: Weak/metric invariance
  Constrain factor loadings equal across groups
  This shows that the construct has the same meaning across groups
  No latent mean difference is estimated
  
Step 3: Strong/scalar invariance
  Constrain item intercepts equal across groups
  Constrain factor loadings
  This is important for assessing mean difference of the latent variable across groups
  Latent mean difference is estimated
  
Step 4: Strict invariance
  Constrain item residual variances to be equal across groups
  Constrain item factor loadings and intercepts equal across groups. 
  Strict invariance is important for group comparisons based on the sum of observed item scores, because observed variance is a combination of true score variance and residual variance
  Latent mean difference is estimated --->
  


```{r measurementinvariance,echo=F,include=F}
#https://towardsdatascience.com/measurement-invariance-definition-and-example-in-r-15b4efcab351


#library(semTools) fits increasingly restrictive models in one command

#same model in different syntax to make it easier to interpret

model.2Fn <- '
f1 =~  A_P1 + B_P2+C_P3+ E_R2
f2 =~  F_R3 + C_P3+D_R1+ E_R2   #2 factor model: no constraint on covariance
'


#measurementInvariance(model=model.2Fn,estimator="WLSMV",data=ddati,group="Handed")
#This gives message to say command is deprecated.
#It gives substantial change to model fit for the final fit.means model.


#NB makeSEMtab2 is a function defined at top of script - just makes it easier to compare parameters across groups

fitM0 <- cfa(model.2Fn,estimator="WLSMV", data = ddati,meanstructure=T)
tabM0 <- makeSEMtab(fitM0)  #

# configural invariance
fitM1 <- cfa(model.2Fn, estimator="WLSMV",data = ddati,meanstructure=T, group = "Handed")

tabM1 <- makeSEMtab2(fitM1,c('_L','_R'))  #in tab1, everything varies for the 2 groups

# weak invariance
fitM2 <- cfa(model.2Fn, ddati, estimator="WLSMV",meanstructure=T,group = "Handed",
            group.equal = "loadings")
tabM2 <- makeSEMtab2(fitM2,c('_L','_R'))
#in tab2, the factor loadings are same for the 2 groups, but everything else can vary


# strong invariance
fitM3 <- cfa(model.2Fn, ddati, estimator="WLSMV",meanstructure=T,group = "Handed",
            group.equal = c("intercepts", "loadings"))
tabM3 <- makeSEMtab2(fitM3,c('_L','_R'))
#THis does have same intercepts and loadings, but the correlation between f1/f2 and the variances of each factor can differ, as well as the residuals.

#strong invariance with covariance between factors too
fitM3a <- cfa(model.2Fn, ddati,estimator="WLSMV",meanstructure=T, group = "Handed",
            group.equal = c("intercepts","loadings","lv.covariances"))
tabM3a <- makeSEMtab2(fitM3a,c('_L','_R'))
# This is not included in usual hierarchy of models but seems relevant for our hypothesis, which assumes the two factors have equivalent correlation in L and R handers?. but including this at step 2 gives error re standardized measures

fitM4 <- cfa(model.2Fn, ddati, estimator="WLSMV",meanstructure=T,group = "Handed",
 group.equal = c("loadings","intercepts","means","lv.covariances"))

tabM4 <- makeSEMtab2(fitM4,c('_L','_R'))

# model comparison tests
mylavtest<-lavTestLRT(fitM1, fitM2, fitM3,fitM3a, fitM4)
```

```{r showlavtest,echo=F,warning=F,message=F}

mylavtest<-add_rownames(mylavtest)
mylavtest<-mylavtest[,-c(3,4)]
myvec<-1:5
mylavtest<-cbind(myvec,mylavtest)
colnames(mylavtest)[1:2]<-c('Model','Group constraints')
mylavtest[,2]<-c('None','Equal loadings','2 + Equal intercepts','3 + Equal factor covariance','4 + Equal factor means')
mylavtest[,4:5]<-round(mylavtest[,4:5],2)

mylavtest[2:5,7]<-pformat2(mylavtest[2:5,7]) #irritatingly, this doesnt give <.001 as it should, because it insists that values are numeric

ft<-flextable(mylavtest)
ft<-autofit(ft)
ft
#see https://users.ugent.be/~yrosseel/lavaan/multiplegroup6Dec2012.pdf
tabnumber<-tabnumber+1

```
 
Table `r tabnumber`: _Nested tests of model equivalence for left and right handers_  

The approach we adopted is a standard one used when structural equation modeling (SEM) is applied to evaluation of measurement models in other domains, where it is described as a test of measurement invariance. Essentially, the data from left- and right-handers are analysed together in a series of nested models; these pose increasingly stringent constraints on which parameters of the model are allowed to vary for the two handedness groups. Initially, a model is fit in which all the paths, covariances, and intercepts are free to differ between left- and right-handers. This model is tested against a model of 'metric invariance', which sets the loadings from each observed variable to the factors to be the same for the two groups. If the fit of the model does not worsen, we can assume the basic model structure is equivalent for the two groups. This test of equivalence was passed (see Table `r tabnumber`).

At the next step, (scalar invariance), the item intercepts are set to be the same across groups. Once again, the model fit did not worsen (see Table `r tabnumber`). We then added a further constraint, which was that the covariance between factors should be the same for the two groups. Again, model fit was not impaired.  

In a final step (strict invariance), we constrain item residual variances as well as factor loadings and intercepts to be equal across groups. Here we obtained a substantial worsening of model fit, indicating that the mean difference between groups on the latent factors is not the same. 

In sum, results from the measurement invariance test showed that, contrary to our prediction, the same underlying structural model can be assumed to apply for both left- and right-handers, with the differences between handedness groups being explained solely in terms of differences in means, rather than in the pattern of covariances between the six LIs. 

## Categorical analysis of LIs  
Prediction 4 was: _On categorical analysis, individuals who depart from left-brained laterality on one or more tasks will be more likely to be left-handed than those who are consistently left-lateralised._

The analysis so far has treated laterality as a continuum, but this continuum does have a zero-point, and negative scores indicate right-lateralisation and positive scores left-lateralisation. There are theoretical reasons to suppose that brain function might be influenced more by consistency in direction of lateralisation, than by degree. Thus, regardless of how strong or weak a laterality index is, brain functioning might be more efficient if all language functions are represented in the same hemisphere. 

As stated in our preregistration, we first adopted the simple approach of dichotomising laterality at a cutoff of zero for each task, and then performed a chi square analysis to test for association with handedness. For 6 measures, we adopted a Bonferroni-corrected alpha level of .02/6 = .003. 

```{r categorical-assignment, echo=F}
mycols<-paste0(LETTERS[1:6],'_mean_LI')
for (i in 1:6){
  c<-which(colnames(ddat)==mycols[i])
  myvector<-rep(NA, nrow(ddat))
  w<-which(ddat[,c]>0.000000001)
  myvector[w]<-1
  w<-which(ddat[,c]<0)
  myvector[w]<-0
  ddat[,(1+ncol(ddat))]<-myvector
  colnames(ddat)[ncol(ddat)] <- paste0(LETTERS[i],'_catlatL')
}
```

```{r category-analysis,echo=F}
chidf <- data.frame(matrix(NA,nrow=6,ncol=5))
colnames(chidf) <- c('Task','pL_Lhander','pL_Rhander','chisq','p')
nucols <- paste0(LETTERS[1:6],'_catlatL')
  myL <- filter(ddat,Handed=='Left')
  myR <- filter(ddat,Handed=='Right')
for (i in 1:6){
    c<-which(colnames(ddat)==nucols[i])
 
  myt<-table(ddat$Handed,ddat[,c])
  chitab<-chisq.test(myt)
  chidf[i,1]<-LETTERS[i]
  chidf[i,2]<-round(sum(myL[,c],na.rm=T)/nrow(myL),3)
  chidf[i,3]<-round(sum(myR[,c],na.rm=T)/nrow(myR),3)
  chidf[i,4]<-round(chitab$statistic,2)
  chidf[i,5]<-pformat2(chitab$p.value)

}
  mydiff <- (chidf[ ,3] - chidf [ , 2]) *100
  chidf$Task<-c('Word Generation','Sentence Generation','Phonological Decision','Word Comprehension','Sentence Comprehension','Syntactic Decision')
  ft<-flextable(chidf)
  autofit(ft)
  
  chidf$diffp<-chidf$pL_Rhander-chidf$pL_Lhander
  tabnumber<-tabnumber+1
  
  
```
Table `r tabnumber`: _Proportions showing left lateralisation on fTCD tasks_

Results are shown in Table `r tabnumber`.  The trend is similar for all six tasks, with the proportion who are left-lateralised averaging at `r round(mean(mydiff), 0)`% lower in left-handers than in right-handers, regardless of the mean LI for the task. The difference ranged from `r round(min(mydiff), 0)`% for Syntactic Decision to `r round(max(mydiff), 0)`% for Sentence Comprehension, but met our prespecified significance criterion only for Sentence Comprehension.

After testing associations for individual measures, we categorised individuals as either consistently left-lateralised on all tests, or right-lateralised on one or more tests. The proportions of left- and right-handers who are left-lateralised on between 0 and 6 tests is shown in table `r tabnumber`. 

Table `r tabnumber+1`: _Proportions of left- and right-handers with between 0 and 6 tasks left-lateralised on fTCD._    




```{r ntestL,echo=F}
ddat$Nleft <- ddat$A_catlatL+ ddat$B_catlatL+ddat$C_catlatL+ddat$D_catlatL+ddat$E_catlatL+ddat$F_catlatL

tabN <- table(ddat$Nleft,ddat$Handed)
tabNp<-round(prop.table(tabN,2),3)
ntestL <- as.data.frame(cbind(0:6,tabNp[,1],tabNp[,2])) #N tests that are L lateralised
colnames(ntestL)<-c('N tasks L lateralised','L-handers','R-handers')

ft<-autofit(flextable(ntestL))
ft
tabnumber<-tabnumber+1

chitab<-matrix(c(sum(tabN[1:6,1]),sum(tabN[1:6,2]),tabN[7,1],tabN[7,2]),nrow=2)
mychi<-chisq.test(chitab)



#Some exploratory analyses folllow
#repeating just for factor 1
ddat$NleftABCE <- ddat$A_catlatL+ ddat$B_catlatL+ddat$C_catlatL+ddat$E_catlatL

tabN4 <- table(ddat$NleftABCE,ddat$Handed)

ntestL_F1 <- round(prop.table(tabN4,2),3)
chitab4<-matrix(c(sum(tabN4[1:4,1]),sum(tabN4[1:4,2]),tabN4[5,1],tabN4[5,2]),nrow=2)
mychi4<-chisq.test(chitab4)



#repeating with L handers subdivided into extreme or moderate 
ddat$hand3cat <- ddat$Rhanded
ddat$hand3cat[ddat$EHI.LI<(-90)]<--1

tabN4a <- table(ddat$NleftABCE,ddat$hand3cat)
ntestL_F1_LHs<-round(prop.table(tabN4a,2),3)

# How many right/left handers are left lateralised for SG?
SG_left_Lprop <- sum(ddat$B_catlatL[which(ddat$Rhanded==0)])/length(ddat$B_catlatL[which(ddat$Rhanded==0)])
SG_right_Lprop <- sum(ddat$B_catlatL[which(ddat$Rhanded==1)])/length(ddat$B_catlatL[which(ddat$Rhanded==1)])

```
It is evident from Table `r tabnumber` that a minority of individuals are consistently left-lateralised on all six tasks, regardless of handedness. The trend is for more right-handers to show this pattern than left-handers, and this difference is significant on chi square test, chi square = `r round(mychi$statistic,2)`, `r pformat(mychi$p.value)`.  However, two of the tests included in this analysis, Word Comprehension and Syntactic Decision, were not left-lateralised at the population level, and it could be argued they would just add noise to the analysis, which was intended to identify those who departed from the typical pattern of left-lateralisation. We therefore added an exploratory analysis, in which we excluded these two tests. When only Word Production, Sentence Production, Phonological Decision and Syntactic Comprehension were considered, `r round(100*tabN4[5,1]/sum(tabN4[1:5,1]),1)`% of left-handers and `r round(100*tabN4[5,2]/sum(tabN4[1:5,2]),1)`% of right-handers were consistently left-lateralised. 

It is noteworthy that this more categorical analysis finds rates of "atypical", i.e. non-left, lateralisation on language tasks that are on the one hand task-dependent, but on the other hand lower than typically observed when methods such as Wada test or fMRI are used. This is the case even for the most lateralised task, Sentence Generation, where `r round(SG_right_Lprop*100, 0)`% of right-handers vs `r round(SG_left_Lprop*100, 0)`% of left-handers were left-lateralised. 

## Relationship between fTCD and behavioural laterality indices

Our fifth prediction was: _the laterality profile obtained with the online language battery will be significantly associated with the profile seen with the direct measurement of cerebral blood flow using fTCD, with laterality on dichotic listening and word comprehension relating more strongly to receptive language tasks, and rhyme decision to language generation tasks._


A preliminary inspection of correlations between online and fTCD laterality indices showed very little relationship between the two, even for the two measures, Word Comprehension and Rhyme Decision, that have analogues in fTCD (tasks D and C respectively).


```{r preparedata,echo=F}
ncol<-ncol(ddati)
for (i in 1:nrow(ddati)){
  mysub <- ddati$ID[i]
  w<-which(combdat$ID==mysub)
  ddati$DL_z[i] <- combdat$DL.zlat.ex[w]
   ddati$RDT_z[i] <- combdat$RDT.zlat.ex[w]
   ddati$WC_z[i] <- combdat$WC.zlat.ex[w]
}

#impute missing values using mice package
nunames<-c('DL_z','RDT_z','WC_z')
thisdat.j <- mice(ddati[,nunames], m=1, maxit = 50, method = 'pmm', seed = 500,print=FALSE)
ddati <-cbind(ddati[,1:12],complete(thisdat.j,1))
```



```{r bigheatmap,echo=F}

 #need to ensure online LIs from excluded are not included
mycolsb<-c("DL_z","RDT_z","WC_z",  "A_P1", "B_P2","C_P3", "D_R1","E_R2", "F_R3")
bigheatmap <- makeheatmap(ddati,mycolsb)
ggsave(paste0(mydir,"/",figdir,"/bigheatmap.png"),width = 6, height = 6)
fignumber<-fignumber+1

```

![Heatmap with online and fTCD measures](bigheatmap.png)  

We had pre-registered two data checks: 1) Online measures that have split-half reliability below .6 will be excluded from further analysis. 2) Online measures of word comprehension and rhyme decision will only be taken forward to the next stage of analysis if they have a correlation of at least .11 with the counterpart measure from fTCD (word comprehension and phonological decision respectively).

The online Word Comprehension measure failed the second check: the correlation with the fTCD Word Comprehension laterality index was close to zero. The correlation between the online Rhyme Decision and fTCD Phonological Decision was `r round(cor(ddati$RDT_z,ddati$C_P3,use='complete.obs'),3)`, meeting our criterion, but split-half reliability was only `r onlinesummary[11,3]`.  Accordingly, we proceeded with the next step of analysis only with Dichotic Listening (which had good reliability, but no counterpart in the fTCD battery).

We had predicted that Dichotic Listening, as a receptive task, should load on the same factor as the Word Comprehension, Sentence Comprehension and Syntactic Decision, but it is evident from the heatmap that, insofar as it correlates with the fTCD tasks, the strongest association is with Sentence Generation, a production task. 



```{r newmodelx,echo=F,include=F}
#Base model: dichotic included but with path set to zero

model.2Fnbase <- '
f1 =~  B_P2+A_P1 +C_P3+ E_R2
f2 =~  NA*F_R3 + C_P3+D_R1+ E_R2 +0*DL_z  #2 factor model:

f2~~1*f2
'

fit.2Fnbase <- cfa(model.2Fnbase,estimator="WLSMV", data=ddati)
summary(fit.2Fnbase)
wantfits <- c('CFI','rmsea','chisq','df')
fitmeasures(fit.2Fn,wantfits)

model.2Fnx <- '
f1 =~  B_P2+A_P1 +C_P3+ E_R2
f2 =~  NA*F_R3 + C_P3+D_R1+ E_R2 +DL_z  #2 factor model, dichotic on Fac2:

f2~~1*f2
'

fit.2Fnx <- cfa(model.2Fnx,estimator="WLSMV", data=ddati)
summary(fit.2Fnx)
wantfits <- c('CFI','rmsea','chisq','df')
fitmeasures(fit.2Fnx,wantfits)




model.2Fny <- '
f1 =~  B_P2+A_P1 +C_P3+ E_R2+DL_z
f2 =~  NA*F_R3 + C_P3+D_R1+ E_R2   #2 factor model, dichotic on Fac1:

f2~~1*f2
'

fit.2Fny <- cfa(model.2Fny,estimator="WLSMV", data=ddati)
summary(fit.2Fny)
wantfits <- c('CFI','rmsea','chisq','df')
fitmeasures(fit.2Fny,wantfits)
fitcompare<-anova(fit.2Fnbase,fit.2Fnx,fit.2Fny)

tab.2Fnbase <- makeSEMtab(fit.2Fnbase)
tab.2Fnx <- makeSEMtab(fit.2Fnx)
tab.2Fny <- makeSEMtab(fit.2Fny)

#measurementInvariance(model=model.2Fny,estimator="WLSMV",data=ddati,meanstructure=T,group="Handed")



pathfigname<-paste0(mydir,"/",figdir,"/pathfigF2_bigA")
semPaths(fit.2Fnx, "diagram", weighted = FALSE,  shapeMan = "rectangle", sizeMan = 8, 
    sizeMan2 = 5,filetype='jpg',filename=pathfigname,width=3,height=2) #draws a path diagram

pathfigname<-paste0(mydir,"/",figdir,"/pathfigF2_bigB")
semPaths(fit.2Fny, "diagram", weighted = FALSE,  shapeMan = "rectangle", sizeMan = 8, 
    sizeMan2 = 5,filetype='jpg',filename=pathfigname,width=3,height=2) #draws a path diagram


#Looking at residuals : dichotic has high variability and big residuals - may be worth trying to scale it - or possibly just censor at a less extreme value
```

```{r models-with-dichotic,echo=F}
modelnames<-c('No dichotic path','Dichotic <- Factor 1','Dichotic <- Factor 2')
dichmodels<-cbind(modelnames,fitcompare[c(3,1,2),])
dichmodels <- dichmodels[,c(1,2,5)]
fd<-flextable(dichmodels)
fd<-autofit(fd)
fd
tabnumber<-tabnumber+1

```
Table `r tabnumber`: _Fit statistics for models including Dichotic Listening_  

In practice, a model including a free path from Dichotic Listening to Factor 2 gave a better fit than a model with the path fixed to zero: chi square difference = `r round(dichmodels$Chisq[1]-dichmodels$Chisq[2],2)`, DF = 1, p < .001. This is not a strong test of our prediction, because it will be passed if there is even a weak correlation between dichotic LI and fTCD laterality indices.  Guided by the data, we ran an alternative model (not pre-registered) with Dichotic Listening loading on Factor 1. This also gave excellent fit, with lower chi square than the preregistered model. 

Overall, the associations between behavioural and fTCD laterality indices were low enough to give little confidence in the specific pattern of associations. The main conclusion is that behavioural measures of laterality based on speed of responding to lateralised stimuli have little in common with measures of relative blood flow to the two hemispheres while performing the same tasks. 


# Discussion

To simplify the interpretation of this complex dataset, we focus first on two overarching questions addressed by the study. The first question concerns correlations between laterality measures: in brief, is there evidence for a single laterality dimension on which people vary? The second question concerns handedness: does the answer to our first question differ in groups of left- and right-handers? In addition we consider specific issues arising in this dataset, namely the finding of right hemisphere lateralisation on Word Comprehension, and the lack of agreement between behavioural and fTCD laterality indices. Finally, we consider how the particular factor structure seen in the fTCD analysis might be explained. 

## Evidence for a single laterality dimension  

Previous attempts to consider the dimensionality of language lateralisation have been obscured by two issues. First, many studies have been conducted with measures whose reliability was not established. If two laterality indices are not correlated, it could just be because they are unreliable, and so it has been easy to dismiss lack of correlation between laterality measures as uninformative. Second, researchers have tended to focus only on measures that show left-lateralisation at the population level, treating unlateralised language measures as uninteresting. 

Considering first the online behavioural data, the most noteworthy observation was that the correlations between laterality indices from the three tasks were generally weak. This could not be attributed solely to poor reliability: although reliabilities of the two new tasks, Rhyme Decision and Word Comprehension, were not impressive (ranging from .54-.55 for test-retest), they were higher than the intercorrelations between measures. Our data was not suitable for a more formal model comparison, but inspection of the pattern of correlations between measures made it clear that our proposed two-factor model, with Dichotic Listening and Word Comprehension being positively correlated and unrelated to Rhyme Decision could not be supported. Indeed, the strongest correlation was found between Word Comprehension and Rhyme Decision, consistent with the idea that task demands (speeded responding to visual pictures) might be a greater determinant of strength of lateralisation than whether receptive or expressive language was involved.  

For the fTCD data, we again found good evidence for reliability of LIs on most tasks, even though some tasks were not left-lateralised. Consistent with Woodhead et al (2021), the LI on Syntactic Decision task had good reliability, and a distinctive pattern of association with other LIs, despite being unlateralised. This observation shows that lack of lateralisation at the population level does not mean that all individuals use both hemispheres equally for the task: it seems rather that the population contains a mixture of people, some of whom consistently prefer the left hemisphere, others the right, and others more equally balanced. The LI from the Word Comprehension task was the least reliable in the battery, yet again showed quite distinctive patterns of selective association with other tasks. In addition, this task showed a trend for right-hemisphere bias, particularly in left-handers. 

With fTCD we were able to subject the single factor model to a stronger test, because we had sufficient tasks for Structural Equation Modeling. Consistent with Woodhead et al (2021), we could reject a single factor model; this gave a poor fit to the data, as it could not account for the fact that the correlations between LIs tended to form clusters. We tested a preregistered alternative two-factor model that involved a division between language production and language reception. This accounted for significantly more variance than the single factor model, but still left a great deal unexplained, and overall the fit was poor. Accordingly, following our preregistration, we divided the sample into two subgroups to explore different models and found one that gave good fit, which was then replicated in the second half of the sample. This again had a two factor structure, but had two of the tasks, Phonological Decision and Syntactic Comprehension, loading on both the factors. 

In a final step of analysis, we considered adding the laterality indices from online tasks to the model. The correlations between LIs from online tasks and fTCD were generally weak, and these measures did not help differentiate models.  A model that included Dichotic Listening gave better fit when a non-zero paths was included, than when it was set to zero, but the best fit was seen for a model where both Dichotic Listening loaded on Factor 1 (with language production tasks), rather than for our prespecified model where Dichotic Listening was regarded as an indicator of Factor 2 (with receptive tasks).

## Left vs Right Handers  
For both online and fTCD LIs, with just one exception, there was a consistent trend for stronger left-hemisphere bias in right-handers than in left-handers. This reached significance on all measures except fTCD Word Comprehension. The exception was online Rhyme Judgement, which was not left-lateralised and where means for left- and right-handers were very similar. 

The SEM analysis allowed us to go beyond simple comparison of means to test whether the association between LIs showed a similar pattern in the two handedness groups. In our previous fTCD study using four of the same measures, we had concluded that there was more dissociation between factors in left-handers, but the sample size was small for this kind of analysis.  Even with the current sample size, power to detect model invariance is limited. Having noted those limitations, our analysis suggested that there was no reason to postulate different models for left- vs right-handers. The substantial differences between these groups could be entirely accounted for in terms of differences in factor means.  As an analogy, we could say this would be like showing that the relationship between height and weight is similar in males and females, even though females are on average shorter and lighter. <!--- not sure that is helpful analogy!--->

## Right hemisphere lateralisation for Word Comprehension
Discussion to be added?

## Differences between behavioural and fTCD measures of laterality
Discussion to be added?

## Interpreting the two-factor structure    
```{r taskanalysis,echo=F}
tasks <- read.csv(paste0(alldir[1],"/04-table-outputs/task_details.csv"))
ftasks <- flextable(tasks[,1:7])

ftasks<-fit_to_width(ftasks,8,inc=1L)
ftasks <- fontsize(ftasks,size=9)
ftasks
tabnumber <- tabnumber+1
```

Table `r tabnumber`: _Characteristics of tasks_  

Table `r tabnumber` summarises the characteristics of the six fTCD tasks, grouped according to the factors they load on. The online Dichotic Listening task is also shown. The task battery had been designed to include three tasks that involved language generation, and three that involved receptive language. As predicted the former loaded on Factor 1 and the latter on Factor 2, but in addition Phonological Decision loaded on Factor 2, and Sentence Comprehension on Factor 1. Phonological Decision, unlike the other tasks loading on Factor 2, did not involve auditory input, but did have in common the 2-choice response format of other Factor 2 tasks. 

Sentence Comprehension also behaved unexpectedly, in that it had significant loadings on Factor 1, despite being designed as a purely receptive task. While it is possible that participants might have covertly repeated sentences to themselves when doing the task, the fast pace of the task made that unlikely, and furthermore, our previous study suggested that simple production of spoken output was not the key attribute of Factor 1 tasks; we had dropped from the current study a List Generation task used by Woodhead, Rutherford and Bishop (2020) that simply involved repeating overlearned sequences such as days of the week, as it had been only weakly lateralised. The Sentence Comprehension task did, however, involve  using syntactic information to assign semantic roles and build meaning representations, and hence more linguistic computation than the tasks that used single word stimuli. 

```{r densplotexplore,echo=F,include=F}

#This uses a function defined above which makes individual density plots by handedness.  Here they are assembled into a column so one can visualise the change in overall laterality.
latcols<-c("A_P1","B_P2","C_P3","D_R1","E_R2","F_R3")
latnames<-c("Word Generation","Sentence Generation","Phonological Decision","Word Comprehension","Sentence Comprehension","Syntactic Decision")
w<-which(colnames(ddati) %in% latcols)
means<-colMeans(ddati[,w])
nuorder <- order(means,decreasing=T)
nucols<-min(w)+nuorder-1
plotlist<-NULL
for (i in 1:6){
  filename<-paste0(mydir,'/',figdir,'/densplot_',i,'.png')
  thiscol<-colnames(ddati)[nucols[i]]
  thisgroup<-'Handed'
  mylab<-latnames[nuorder[i]]
  thisplot <- densplots(ddati,thiscol,thisgroup,mylab)
  ggsave(filename,width = 6, height = 3)
  #There should be a way to avoid the next bit of clunky code!
  d6<-thisplot
  if(i==1){d1<-thisplot}
  if(i==2){d2<-thisplot}
  if(i==3){d3<-thisplot}
  if(i==4){d4<-thisplot}
  if(i==5){d5<-thisplot}

}
alldens <- ggarrange(d1,d2,d3,d4,d5,d6, ncol = 1, nrow = 6,common.legend=TRUE)
ggsave(paste0(mydir,"/",figdir,"alldens.png"),width = 3, height = 7)

```

<!---![Density plots showing LIz scores for six fTCD tasks ordered by overall left-hemisphere bias.](Dropbox/COLA_RR_Analysis/03-graphic-outputs/alldens.png)
Nice density plots but they really just show same information as the pirate plots, so not so sure we need them here?-->
In Figure `r piratenumber` the six fTCD tasks are ordered according to the population bias to left-hemisphere processing, and it can be seen that the four tasks that load on Factor 1 are all significantly lateralised, at least in right-handers. In contrast, those loading on Factor 2 include two tasks that are not significantly lateralised.  

In interpreting this finding, we should first rule out two trivial explanations for the factor structure uncovered in SEM. First, this structure cannot be regarded as an artefact of including tasks differing in degree of laterality. This is because factor structure in SEM is computed solely on the basis of covariances between measures, and means do not affect it. Thus, we could add a constant to the means for tasks D and E to make them lateralised, and the factor solution would remain the same. 

Second, we can rule out an explanation that treats the  non-lateralised tasks as not relevant for studying individual differences in laterality. Such an explanation would be justified if tasks such as Word Comprehension, Sentence Comprehension and Syntactic Decision were simply unreliable. Low reliability would be expected if these tasks were not lateralised in individuals, because people used both hemispheres jointly, or switched from one to the other at random. The new task, Word Comprehension, was the least reliable in the battery, but nevertheless, the split-half reliability indicated was moderate. The other two receptive tasks had good test-retest reliability in our previous study (Woodhead et al, 2021) and good split-half reliability in the current study. Thus, even though there is weak or absent lateralisation at the population level on these tasks, the degree and direction of lateralisation is reasonably consistent within individuals. And indeed, if that were not the case, we would not expect the tasks to show moderate intercorrelations with one another. 

To account for the observed pattern of results, we postulate two language centres, one lateralised at the population level (centre L), and the other centred on zero (centre Z). An individual's observed fTCD laterality on a task will depend on the extent to which these two centres are implicated in task performance, with Word Generation and Sentence Generation being largely dominated by centre L, Syntactic Decision and Word Comprehension by centre Z, and Phonological Decision and Sentence Comprehension implicating both centres. 

To some extent, this is less of an explanation than a redescription of the data, but it does yield novel predictions that can be tested using fMRI, which gives information on localisation of activation within a hemisphere. The prediction would be that there would be more overlap in brain regions activated by tasks that load on the same Factor than for those loading on different Factors, and furthermore, activation would only be lateralised for brain regions supporting Factor 1 tasks.  


## Supplementary materials  

### Supplementary Figure `r suppfignumber+1`

![Density plots and scatterplot showing relationship between conventional laterality index and LIz for dichotic listening.](Afig4_DLdens.png)



```{r anothertryfactors,echo=F}
#Trying to extract factor scores that are not centred on zero.
#Not sure this is legit!
mys<-standardizedSolution(fit.2Fn)
wts1 <- mys$est.std[1:4]
wts2 <-mys$est.std[5:8]
ddati$fac1s<-wts1[1]*ddati$A_P1+
  wts1[2]*ddati$B_P2+
  wts1[3]*ddati$C_P3+
  wts1[4]*ddati$E_R2

ddati$fac2s<-wts2[1]*ddati$F_R3+
  wts2[2]*ddati$C_P3+
  wts2[3]*ddati$D_R1+
  wts2[4]*ddati$E_R2

myx<-ddati$fac1s
myy<-ddati$fac2s
mygroup<- ddati$Handed
mydat<-as.data.frame(cbind(myx,myy,mygroup))
mydat$mygroup<-as.factor(mydat$mygroup)
namex<-'Factor 1'
namey<-"Factor 2"
namegroup <- "Handedness"
grouplabels<- c("Left","Right")
mylines<-2 #horiz and vertical lines showing zero
mytitle <- "Factors derived from standardized weighted \nsum from modified 2 factor model"
mycompositeplot <- dodensity(mydat,myx,myy,mygroup,namex,namey,namegroup,grouplabels,mylines,mytitle)

mycompositeplot
ggsave(paste0(mydir,"/",figdir,"/standfactors.png"),width = 5, height = 4)


```

Not sure whether to include plot showing factor scores as above


